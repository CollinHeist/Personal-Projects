{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code below to load the two accompanying files.\n",
    "\n",
    "coordinate_data.pickle contains the coordinates of 4 points in 3D space (coord_X), and the volume of the solid formed by using those 4 points as vertices (coord_y).\n",
    "NOTE: coord_X has already been centered about the origin, and then reshaped into (N, 12) so it is ready to use in the \"k hidden layers\" class.\n",
    "\n",
    "distance_data.pickle contains the 6 pairwise distances of 4 points in 3D space (dist_X), and the volume of the solid formed by using those 4 points as vertices (dist_y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def pickle_load(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        contents = pickle.load(f)\n",
    "        return contents\n",
    "    return contents\n",
    "\n",
    "# the network will throw errors without the reshaping of y\n",
    "coord_X, coord_y = pickle_load('coordinate_data.pickle')\n",
    "coord_y = np.reshape(coord_y, (-1, 1))\n",
    "dist_X, dist_y = pickle_load('distance_data.pickle')\n",
    "dist_y = np.reshape(dist_y, (-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "\n",
    "As always, rename this file to include your first and last name before submitting.\n",
    "\n",
    "Split up the data into a training set and validation set (use 1% of the data for validation)\n",
    "\n",
    "Use the k_hidden_layer class that Frank posted to train two neural networks: one that can predict the volume of the solid based on the coordinate data, and another that can predict the volume based on the pairwise distances.\n",
    "\n",
    "The current setup of k_hidden_layer is using the crossentropy loss function, which works well for classification (like on MNIST), but does not make sense for for a regression problem like this one (you should make sure you understand why this is by looking at how crossentropy is formulated).  You will need to rewrite that part of the code to implement the mean squared error (MSE) loss function defined below.  There are three parts you need to edit: the gradient calculation, the loss, and you need to print the loss instead of accuracy.\n",
    "\n",
    "$$ \\text{MSE Loss:} L = \\frac{1}{n} \\sum_{i=1}^{n} (y_{i, pred} - y_{i, true})^2 \\hspace{1 cm} \\text{(where n is the batch size)}$$\n",
    "\n",
    "NOTE: To get the training to work well you will need to also look at the distribution of y (see the code below).  One of the most important data preprocessing steps is making sure your labels are spread out evenly (Why?).  The ideal is a uniform distribution, but a normal distribution is often good enough.  To get y to have a (roughly) uniform distribution you can use a one-to-one function like log, or nth root on y for training (or a combination of one-to-one functions), then apply the inverse of the function on your predictions when you want to make a prediction.  Print out the histogram of your transformed data using the code below (you should be able to get it to look like a normal distribution without too much work).\n",
    "\n",
    "Make sure to play around with the structure of your network (the number of hidden layers, and number of nodes in each layer), and the learning rate.  Try to get the validation loss to decrease steadily.\n",
    "\n",
    "Answer the following questions (either in Markdown, or in commented code): Which type of data was better for predicting the volume? Would you expect that data type to be better? Why or why not?\n",
    "\n",
    "I have copied the working k_hidden_layer class to this notebook below.\n",
    "\n",
    "Please send any questions to dfurman@uidaho.edu, or use office hours for help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "redistribute_y_func = lambda y: y ** (1 / 4.0)\n",
    "redistribute_x_func = lambda x: x ** 4.0\n",
    "\n",
    "coord_y2 = redistribute_y_func(coord_y)\n",
    "dist_y2 = redistribute_y_func(dist_y)\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.title('Uniformly Distributed Y-Coordinates')\n",
    "plt.hist(coord_y2, bins=30)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title('Uniformly Distributed Y-Distances')\n",
    "plt.hist(dist_y2, bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class k_hidden_layer(object):\n",
    "    def __init__(self, sizes):\n",
    "        self.num_layers = len(sizes)\n",
    "        self.Bs = [np.zeros((1,size)) for size in sizes[1:]]\n",
    "        self.Ws = [np.random.randn(m,n)/np.sqrt(m) for m, n in zip(sizes[:-1], sizes[1:])]\n",
    "\n",
    "    def loss(self, X, y=None, reg=0.0):\n",
    "        # Move the current input (X) through the network by multiplying it by each weights\n",
    "        Out = np.dot(X, self.Ws[0]) + self.Bs[0]\n",
    "        Outs=[Out]\n",
    "        for W, B in zip(self.Ws[1:], self.Bs[1:]):\n",
    "            Out = np.dot(np.maximum(0, Out), W) + B # Out is the final output of the input after the system\n",
    "            Outs.append(Out)\n",
    "        if y is None:\n",
    "            return Outs\n",
    "        \n",
    "        N = X.shape[0] # How large the input batch is\n",
    "        M = np.max(Out, axis=1, keepdims=True) # M is the most likely output (max column) for each input (row)\n",
    "        Q = np.exp(Out - M)\n",
    "#         Q = np.exp(Out - M) / np.sum(np.exp(Out - M), axis = 1, keepdims=True) # Q is the probability of each 'class' of the output\n",
    "        P = y # P is the actual desired output\n",
    "#         L = -np.mean(np.log(Q[range(N), y]+1e-300)) # Add eps to avoid overflow, implements: -1/N*sum(log(y_i_pred)*y_i_true)\n",
    "        L = np.mean((Q - y) ** 2)\n",
    "        for W in self.Ws:\n",
    "            L += reg * np.sum(W ** 2)\n",
    "            \n",
    "        dWs = [np.zeros_like(W) for W in self.Ws]\n",
    "        dBs = [np.zeros_like(B) for B in self.Bs]\n",
    "        dOuts = [np.zeros_like(Out) for Out in Outs]\n",
    "        dOuts[-1] = (Q - P) / N\n",
    "        \n",
    "        for i in range(2, self.num_layers):\n",
    "            dOuts[-i] = (Outs[-i] > 0) * np.dot(dOuts[-i+1], self.Ws[-i+1].T)\n",
    "        dBs[0] = np.sum(dOuts[0], axis=0, keepdims=True)\n",
    "        dWs[0] = np.dot(X.T, dOuts[0]) + 2 * reg * self.Ws[0]\n",
    "        \n",
    "        for layer in range(1, self.num_layers - 1):    \n",
    "            dBs[layer] = np.sum(dOuts[layer], axis=0, keepdims=True)\n",
    "            dWs[layer] = np.dot(np.maximum(0,Outs[layer-1]).T,dOuts[layer])\n",
    "            dWs[layer] += 2 * reg * self.Ws[layer]\n",
    "            \n",
    "        return L, dBs, dWs\n",
    "    \n",
    "    def train(self, X_train, y_train, X_val=None, y_val=None,\n",
    "              learning_rate=1e-3, learning_rate_decay=0.99,\n",
    "              reg=5e-3, epochs=5, batch_size=20, verbose=False): # batch_size was 60\n",
    "        loss_history = []\n",
    "        train_acc_history = []\n",
    "        val_acc_history = []\n",
    "        N = X_train.shape[0]\n",
    "        iteration=0\n",
    "        for epoch in range(epochs):\n",
    "            perm = np.arange(N)\n",
    "            np.random.shuffle(perm)\n",
    "            X_batches = [X_train[perm[k:k+batch_size]] for k in range(0, N, batch_size)]\n",
    "            y_batches = [y_train[perm[k:k+batch_size]] for k in range(0, N, batch_size)]\n",
    "            for X,y in zip(X_batches, y_batches):\n",
    "                L, dBs, dWs = self.loss(X, y, reg)\n",
    "                self.Ws = [W - learning_rate * dW for W,dW in zip(self.Ws, dWs)]\n",
    "                self.Bs = [B - learning_rate * dB for B,dB in zip(self.Bs, dBs)]\n",
    "                \n",
    "                if iteration % 100 == 0:  \n",
    "                    print (self.Ws)\n",
    "                    loss_history.append(L)   \n",
    "                    y_pred = self.predict(X)\n",
    "                    train_acc = np.mean(y_pred==y) \n",
    "                    train_acc_history.append(train_acc)                               \n",
    "                    if X_val is not None:\n",
    "                        y_val_pred = self.predict(X_val)\n",
    "                        val_acc = np.mean(y_val_pred==y_val) \n",
    "                        val_acc_history.append(val_acc)\n",
    "                    if verbose:\n",
    "                        if X_val is not None:\n",
    "                            print('iteration %d: loss %f, train_acc: %f, val_acc: %f' \n",
    "                                  % (iteration, L, train_acc, val_acc))\n",
    "                        else:\n",
    "                            print('iteration %d: loss %f, train_acc: %f' \n",
    "                                  % (iteration, L, train_acc))\n",
    "                iteration += 1\n",
    "            if X_val is not None:\n",
    "                print('Epoch ', epoch+1, 'validation accuracy: ', val_acc)\n",
    "            else:\n",
    "                print('Epoch ', epoch+1, 'completed.')\n",
    "            learning_rate*=learning_rate_decay\n",
    "            \n",
    "        return {'loss_history': loss_history, 'train_acc_history': train_acc_history, 'val_acc_history': val_acc_history}\n",
    "               \n",
    "    def predict(self, X):\n",
    "        y_pred=np.argmax(self.loss(X)[-1], axis=1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subdivide_data(x, y, test_percentage=0.025):\n",
    "    assert len(x) == len(y), \"Lengths of x and y must be equal.\"\n",
    "    indices = np.arange(len(x))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    return {\"X-Train\": x[indices][:int(len(x) * (1.0 - test_percentage))],\n",
    "            \"Y-Train\": y[indices][:int(len(x) * (1.0 - test_percentage))],\n",
    "            \"X-Test\": x[indices][-int(len(x) * test_percentage):],\n",
    "            \"Y-Test\": y[indices][-int(len(x) * test_percentage):]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-Train[0]: [-0.36 -3.33  0.5   3.19  2.08 -1.88  1.27 -1.47 -0.17 -1.02  0.28  0.9 ]\n",
      "Y-Train[0]: [4.77]\n",
      "X-Test[0]: [-0.73  0.75 -0.1   0.08  5.26 -0.93  1.6  -5.94  3.85 -4.   -0.19  0.34]\n",
      "Y-Test[0]: [9.24]\n"
     ]
    }
   ],
   "source": [
    "data_dict = subdivide_data(coord_X, coord_y)\n",
    "for key in data_dict.keys():\n",
    "    with np.printoptions(precision=2):\n",
    "        print (\"{}[0]: {}\".format(key, data_dict[key][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.38, -0.29, -0.15],\n",
      "       [-0.44, -0.29, -0.34],\n",
      "       [ 0.41,  0.55,  0.05],\n",
      "       [-0.11, -0.03,  0.37],\n",
      "       [ 0.17,  0.29,  0.21],\n",
      "       [-0.02,  0.37,  0.3 ],\n",
      "       [ 0.3 , -0.05, -0.09],\n",
      "       [ 0.01,  0.91,  0.18],\n",
      "       [ 0.08,  0.04, -0.2 ],\n",
      "       [ 0.19, -0.17,  0.13],\n",
      "       [-0.17, -0.33, -0.09],\n",
      "       [-0.41,  0.16,  0.14]]), array([[-0.12],\n",
      "       [ 0.42],\n",
      "       [-1.23]])]\n",
      "[array([[-2.16e+04, -9.29e+04, -5.98e-02],\n",
      "       [-3.63e+03, -4.07e+03, -5.60e-03],\n",
      "       [ 1.18e+03,  9.00e+03, -1.37e-02],\n",
      "       [ 2.41e+04,  8.80e+04,  1.25e-02],\n",
      "       [-1.94e+04, -6.27e+04,  1.31e-01],\n",
      "       [-5.23e+04, -1.03e+05,  1.69e-01],\n",
      "       [-2.13e+04, -6.62e+04,  1.62e-01],\n",
      "       [ 9.30e+04,  2.32e+05,  1.36e-01],\n",
      "       [-9.66e+03, -7.72e+03, -1.23e-02],\n",
      "       [ 5.57e+04,  7.89e+04,  1.54e-02],\n",
      "       [-4.98e+04, -1.31e+05,  5.03e-03],\n",
      "       [ 3.75e+03,  5.97e+04, -3.07e-02]]), array([[ 1.34e+05],\n",
      "       [ 3.31e+05],\n",
      "       [-6.59e-01]])]\n",
      "[array([[-1.02e+10, -2.60e+10, -5.98e-02],\n",
      "       [-2.59e+10, -6.14e+10, -5.59e-03],\n",
      "       [ 2.05e+10,  5.25e+10, -1.37e-02],\n",
      "       [ 1.56e+10,  3.48e+10,  1.25e-02],\n",
      "       [-1.41e+10, -3.39e+10,  1.31e-01],\n",
      "       [-1.33e+10, -3.20e+10,  1.68e-01],\n",
      "       [-4.03e+09, -9.89e+09,  1.61e-01],\n",
      "       [ 3.14e+10,  7.58e+10,  1.36e-01],\n",
      "       [ 1.95e+10,  4.82e+10, -1.23e-02],\n",
      "       [ 2.44e+10,  5.99e+10,  1.53e-02],\n",
      "       [-1.46e+10, -3.38e+10,  5.02e-03],\n",
      "       [-2.92e+10, -7.44e+10, -3.06e-02]]), array([[ 6.77e+10],\n",
      "       [ 1.65e+11],\n",
      "       [-6.59e-01]])]\n",
      "[array([[-2.69e+15, -6.56e+15, -5.97e-02],\n",
      "       [-1.18e+16, -2.88e+16, -5.59e-03],\n",
      "       [ 3.63e+15,  8.83e+15, -1.37e-02],\n",
      "       [ 1.09e+16,  2.65e+16,  1.25e-02],\n",
      "       [-5.69e+15, -1.38e+16,  1.31e-01],\n",
      "       [ 3.12e+15,  7.58e+15,  1.68e-01],\n",
      "       [ 3.12e+15,  7.59e+15,  1.61e-01],\n",
      "       [-5.49e+14, -1.34e+15,  1.36e-01],\n",
      "       [-4.27e+15, -1.04e+16, -1.22e-02],\n",
      "       [ 5.15e+15,  1.25e+16,  1.53e-02],\n",
      "       [-3.07e+15, -7.46e+15,  5.02e-03],\n",
      "       [ 2.19e+15,  5.32e+15, -3.06e-02]]), array([[ 1.83e+16],\n",
      "       [ 4.45e+16],\n",
      "       [-6.58e-01]])]\n",
      "[array([[-1.76e+21, -4.28e+21, -4.26e-02],\n",
      "       [-7.16e+20, -1.74e+21, -7.21e-03],\n",
      "       [ 5.18e+20,  1.26e+21, -1.58e-02],\n",
      "       [ 1.96e+21,  4.76e+21, -7.04e-04],\n",
      "       [-3.61e+20, -8.78e+20,  1.34e-01],\n",
      "       [ 6.22e+20,  1.51e+21,  1.52e-01],\n",
      "       [ 4.49e+19,  1.09e+20,  1.88e-01],\n",
      "       [-3.06e+20, -7.45e+20,  1.21e-01],\n",
      "       [ 5.87e+20,  1.43e+21,  1.51e-02],\n",
      "       [ 1.13e+20,  2.76e+20,  7.25e-04],\n",
      "       [-1.85e+20, -4.50e+20,  3.81e-02],\n",
      "       [-5.16e+20, -1.25e+21, -7.64e-02]]), array([[ 2.96e+21],\n",
      "       [ 7.20e+21],\n",
      "       [-6.49e-01]])]\n",
      "[array([[ 4.83e+25,  1.17e+26, -4.05e-02],\n",
      "       [-3.22e+26, -7.84e+26, -1.21e-02],\n",
      "       [ 2.70e+26,  6.57e+26, -1.16e-02],\n",
      "       [ 4.05e+24,  9.85e+24, -2.13e-03],\n",
      "       [ 3.96e+25,  9.63e+25,  1.34e-01],\n",
      "       [ 1.07e+26,  2.60e+26,  1.55e-01],\n",
      "       [-1.15e+26, -2.79e+26,  1.70e-01],\n",
      "       [-3.18e+25, -7.73e+25,  1.36e-01],\n",
      "       [-7.78e+25, -1.89e+26, -1.40e-02],\n",
      "       [-1.36e+26, -3.31e+26,  9.73e-03],\n",
      "       [ 5.35e+25,  1.30e+26,  3.43e-02],\n",
      "       [ 1.60e+26,  3.90e+26, -5.25e-02]]), array([[ 5.04e+26],\n",
      "       [ 1.23e+27],\n",
      "       [-6.47e-01]])]\n",
      "[array([[-4.78e+31, -1.16e+32, -4.04e-02],\n",
      "       [ 9.78e+30,  2.38e+31, -1.21e-02],\n",
      "       [-6.54e+31, -1.59e+32, -1.16e-02],\n",
      "       [ 1.03e+32,  2.52e+32, -2.13e-03],\n",
      "       [-1.69e+32, -4.11e+32,  1.34e-01],\n",
      "       [-6.06e+31, -1.47e+32,  1.55e-01],\n",
      "       [ 7.55e+31,  1.84e+32,  1.70e-01],\n",
      "       [ 1.54e+32,  3.75e+32,  1.36e-01],\n",
      "       [-3.64e+32, -8.86e+32, -1.40e-02],\n",
      "       [ 5.88e+31,  1.43e+32,  9.72e-03],\n",
      "       [ 2.93e+31,  7.14e+31,  3.43e-02],\n",
      "       [ 2.76e+32,  6.72e+32, -5.24e-02]]), array([[ 5.31e+32],\n",
      "       [ 1.29e+33],\n",
      "       [-6.47e-01]])]\n",
      "[array([[-8.80e+37, -2.14e+38, -7.99e-03],\n",
      "       [ 4.20e+37,  1.02e+38, -5.15e-02],\n",
      "       [-1.38e+37, -3.36e+37, -2.70e-03],\n",
      "       [ 5.99e+37,  1.46e+38, -3.94e-03],\n",
      "       [ 6.23e+37,  1.52e+38,  1.53e-01],\n",
      "       [-1.38e+37, -3.35e+37,  1.58e-01],\n",
      "       [-2.14e+37, -5.20e+37,  1.30e-01],\n",
      "       [-2.72e+37, -6.62e+37,  1.53e-01],\n",
      "       [-1.94e+37, -4.71e+37, -1.21e-02],\n",
      "       [ 3.39e+37,  8.25e+37, -9.84e-03],\n",
      "       [ 2.88e+37,  7.00e+37, -1.56e-03],\n",
      "       [-4.33e+37, -1.05e+38,  1.10e-03]]), array([[ 1.36e+38],\n",
      "       [ 3.31e+38],\n",
      "       [-6.43e-01]])]\n",
      "[array([[ 4.54e+42,  1.11e+43, -7.98e-03],\n",
      "       [-1.19e+43, -2.90e+43, -5.15e-02],\n",
      "       [-7.67e+41, -1.87e+42, -2.70e-03],\n",
      "       [ 8.16e+42,  1.99e+43, -3.94e-03],\n",
      "       [ 2.12e+43,  5.15e+43,  1.53e-01],\n",
      "       [-5.78e+42, -1.41e+43,  1.58e-01],\n",
      "       [-1.56e+43, -3.79e+43,  1.30e-01],\n",
      "       [ 1.71e+41,  4.16e+41,  1.53e-01],\n",
      "       [ 1.30e+43,  3.15e+43, -1.21e-02],\n",
      "       [-1.42e+43, -3.45e+43, -9.83e-03],\n",
      "       [-1.68e+43, -4.09e+43, -1.56e-03],\n",
      "       [ 1.80e+43,  4.38e+43,  1.10e-03]]), array([[ 4.15e+43],\n",
      "       [ 1.01e+44],\n",
      "       [-6.42e-01]])]\n",
      "[array([[-3.49e+48, -8.49e+48, -7.97e-03],\n",
      "       [ 5.71e+48,  1.39e+49, -5.14e-02],\n",
      "       [-1.22e+48, -2.96e+48, -2.69e-03],\n",
      "       [-1.00e+48, -2.44e+48, -3.93e-03],\n",
      "       [ 5.43e+48,  1.32e+49,  1.52e-01],\n",
      "       [-6.00e+48, -1.46e+49,  1.58e-01],\n",
      "       [ 3.33e+48,  8.11e+48,  1.30e-01],\n",
      "       [-2.77e+48, -6.73e+48,  1.53e-01],\n",
      "       [-1.13e+46, -2.75e+46, -1.21e-02],\n",
      "       [-4.35e+47, -1.06e+48, -9.82e-03],\n",
      "       [ 2.42e+48,  5.90e+48, -1.55e-03],\n",
      "       [-1.98e+48, -4.81e+48,  1.09e-03]]), array([[ 1.12e+49],\n",
      "       [ 2.73e+49],\n",
      "       [-6.42e-01]])]\n",
      "[array([[ 1.76e+54,  4.28e+54, -7.96e-03],\n",
      "       [ 1.05e+54,  2.56e+54, -5.14e-02],\n",
      "       [-5.44e+53, -1.32e+54, -2.69e-03],\n",
      "       [-2.26e+54, -5.51e+54, -3.93e-03],\n",
      "       [-6.34e+53, -1.54e+54,  1.52e-01],\n",
      "       [-4.92e+52, -1.20e+53,  1.58e-01],\n",
      "       [-3.51e+53, -8.54e+53,  1.30e-01],\n",
      "       [ 1.03e+54,  2.52e+54,  1.52e-01],\n",
      "       [ 6.27e+53,  1.53e+54, -1.21e-02],\n",
      "       [-1.50e+54, -3.65e+54, -9.81e-03],\n",
      "       [-3.11e+52, -7.56e+52, -1.55e-03],\n",
      "       [ 9.05e+53,  2.20e+54,  1.09e-03]]), array([[ 3.52e+54],\n",
      "       [ 8.57e+54],\n",
      "       [-6.41e-01]])]\n",
      "[array([[ 2.83e+59,  6.88e+59, -7.95e-03],\n",
      "       [-9.08e+58, -2.21e+59, -5.13e-02],\n",
      "       [-1.10e+59, -2.68e+59, -2.69e-03],\n",
      "       [-8.18e+58, -1.99e+59, -3.93e-03],\n",
      "       [-1.94e+59, -4.73e+59,  1.52e-01],\n",
      "       [ 1.04e+59,  2.52e+59,  1.57e-01],\n",
      "       [-3.27e+59, -7.95e+59,  1.29e-01],\n",
      "       [ 4.18e+59,  1.02e+60,  1.52e-01],\n",
      "       [ 1.73e+59,  4.21e+59, -1.21e-02],\n",
      "       [-2.11e+59, -5.13e+59, -9.80e-03],\n",
      "       [-1.66e+59, -4.03e+59, -1.55e-03],\n",
      "       [ 2.03e+59,  4.95e+59,  1.09e-03]]), array([[ 7.59e+59],\n",
      "       [ 1.85e+60],\n",
      "       [-6.40e-01]])]\n",
      "[array([[ 4.09e+64,  9.95e+64, -7.95e-03],\n",
      "       [ 2.20e+64,  5.36e+64, -5.13e-02],\n",
      "       [-3.27e+64, -7.97e+64, -2.69e-03],\n",
      "       [-3.02e+64, -7.34e+64, -3.92e-03],\n",
      "       [ 4.54e+64,  1.10e+65,  1.52e-01],\n",
      "       [-7.15e+64, -1.74e+65,  1.57e-01],\n",
      "       [-4.67e+64, -1.14e+65,  1.29e-01],\n",
      "       [ 7.27e+64,  1.77e+65,  1.52e-01],\n",
      "       [ 1.88e+64,  4.57e+64, -1.21e-02],\n",
      "       [ 3.76e+64,  9.16e+64, -9.79e-03],\n",
      "       [ 3.01e+64,  7.32e+64, -1.55e-03],\n",
      "       [-8.65e+64, -2.10e+65,  1.09e-03]]), array([[ 1.69e+65],\n",
      "       [ 4.11e+65],\n",
      "       [-6.40e-01]])]\n",
      "[array([[-2.36e+69, -5.74e+69, -7.94e-03],\n",
      "       [ 2.80e+69,  6.80e+69, -5.12e-02],\n",
      "       [ 2.53e+69,  6.15e+69, -2.68e-03],\n",
      "       [-2.97e+69, -7.22e+69, -3.92e-03],\n",
      "       [ 1.44e+70,  3.50e+70,  1.52e-01],\n",
      "       [-5.52e+69, -1.34e+70,  1.57e-01],\n",
      "       [-9.82e+69, -2.39e+70,  1.29e-01],\n",
      "       [ 9.71e+68,  2.36e+69,  1.52e-01],\n",
      "       [-6.76e+69, -1.64e+70, -1.20e-02],\n",
      "       [ 3.81e+69,  9.28e+69, -9.78e-03],\n",
      "       [-5.32e+69, -1.29e+70, -1.55e-03],\n",
      "       [ 8.27e+69,  2.01e+70,  1.09e-03]]), array([[ 2.26e+70],\n",
      "       [ 5.51e+70],\n",
      "       [-6.39e-01]])]\n",
      "[array([[ 8.83e+74,  2.15e+75, -7.93e-03],\n",
      "       [ 7.46e+73,  1.81e+74, -5.12e-02],\n",
      "       [-1.01e+75, -2.45e+75, -2.68e-03],\n",
      "       [ 4.84e+73,  1.18e+74, -3.91e-03],\n",
      "       [-1.48e+74, -3.59e+74,  1.52e-01],\n",
      "       [ 3.89e+74,  9.47e+74,  1.57e-01],\n",
      "       [-4.62e+74, -1.12e+75,  1.29e-01],\n",
      "       [ 2.20e+74,  5.36e+74,  1.52e-01],\n",
      "       [-1.60e+74, -3.89e+74, -1.20e-02],\n",
      "       [-5.80e+74, -1.41e+75, -9.77e-03],\n",
      "       [-7.34e+74, -1.79e+75, -1.55e-03],\n",
      "       [ 1.47e+75,  3.58e+75,  1.09e-03]]), array([[ 2.34e+75],\n",
      "       [ 5.69e+75],\n",
      "       [-6.38e-01]])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 1.62e+80,  3.93e+80, -7.92e-03],\n",
      "       [-2.42e+78, -5.88e+78, -5.11e-02],\n",
      "       [-9.35e+78, -2.28e+79, -2.68e-03],\n",
      "       [-1.50e+80, -3.64e+80, -3.91e-03],\n",
      "       [ 2.23e+80,  5.43e+80,  1.52e-01],\n",
      "       [ 1.24e+80,  3.02e+80,  1.57e-01],\n",
      "       [-1.83e+80, -4.46e+80,  1.29e-01],\n",
      "       [-1.64e+80, -3.99e+80,  1.52e-01],\n",
      "       [ 1.04e+79,  2.54e+79, -1.20e-02],\n",
      "       [ 1.59e+80,  3.86e+80, -9.76e-03],\n",
      "       [-3.92e+80, -9.55e+80, -1.54e-03],\n",
      "       [ 2.23e+80,  5.43e+80,  1.09e-03]]), array([[ 6.34e+80],\n",
      "       [ 1.54e+81],\n",
      "       [-6.38e-01]])]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-bc2b638f5025>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mNetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_hidden_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mNetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X-Train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y-Train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X-Test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y-Test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-88-f15a3a09c283>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_train, y_train, X_val, y_val, learning_rate, learning_rate_decay, reg, epochs, batch_size, verbose)\u001b[0m\n\u001b[1;32m     68\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mX_val\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                         \u001b[0my_val_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                         \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val_pred\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                         \u001b[0mval_acc_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Network = k_hidden_layer([12, 3, 1])\n",
    "Network.train(data_dict['X-Train'], data_dict['Y-Train'], data_dict['X-Test'], data_dict['Y-Test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
