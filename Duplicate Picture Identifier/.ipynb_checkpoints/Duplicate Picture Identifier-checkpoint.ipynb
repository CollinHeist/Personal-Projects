{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicate Picture Identifier\n",
    "##### by Collin Heist\n",
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjustable Variables\n",
    "- `time_per__compare` is how long each comparison takes (taken experimentally)\n",
    "- `hash_threshold` is the maximum acceptable value for a difference between two hashes that will be counted as similar\n",
    "- `progress_report_amount` is how often (in images) to update the user\n",
    "- `moxe_extensions` is a tuple of valid file formats that will be moved when sorting files\n",
    "- `dupe_extensions` is a tuple of valid file formats that are hashed and compared for duplicate identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_per_compare = 1e-4\n",
    "hash_threshold = 3\n",
    "progress_report_frequency = 500\n",
    "video_extensions = ('.mov', '.mp4', '.gif')\n",
    "image_extensions = ('.jpg', '.jpeg', '.png', '.heic')\n",
    "dupe_extensions = (\".jpg\", \".jpeg\", \".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get the image list\n",
    "This function takes a given directory and returns all files that fit either the move or duplicate extension criteria, as set by the value of `move`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_list(path, ignore_list=[None], move=True, videos=False):\n",
    "    list_of_files = os.listdir(path) # Get a list of all files in the current directory\n",
    "    all_files = []\n",
    "    # Iterate over all the entries\n",
    "    for entry in list_of_files:\n",
    "        # Create full path\n",
    "        full_path = os.path.join(path, entry)\n",
    "        # If entry is a directory then get the list of files in this directory \n",
    "        if os.path.isdir(full_path) and entry not in ignore_list:\n",
    "            all_files = all_files + get_image_list(full_path, ignore_list, move, videos)\n",
    "        else:\n",
    "            all_files.append(full_path)\n",
    "                            \n",
    "    # Return a filtered list that only contains files who end in the valid extension\n",
    "    if move is False: # Duplicates being identified\n",
    "        return [image for image in all_files if image.lower().endswith(dupe_extensions)]\n",
    "    elif move is True and videos is False: # Moving images\n",
    "        return [image for image in all_files if image.lower().endswith(image_extensions)]\n",
    "    elif move is True and videos is True: # Moving videos\n",
    "        return [image for image in all_files if image.lower().endswith(video_extensions)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to estimate the number of comparisons performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_comparisons(image_list):\n",
    "    return int(len(image_list) * (len(image_list) + 1) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to check all images in a given path for duplicates\n",
    "This is the coup de gr√¢ce; all images in the provided path are compared, duplicates are identified and a convenient `DataFrame` is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_duplicates(path, ignore_list=[None], verbose=True):\n",
    "    image_list = get_image_list(path, ignore_list=ignore_list, move=False)\n",
    "    if verbose:\n",
    "        print (\"{} images, requiring {} comparisons\".format(len(image_list), num_comparisons(image_list)))\n",
    "        print (\"This should take about {} minutes\".format(int(time_per_compare * num_comparisons(image_list) / 60.0)))\n",
    "        start_time = time.time() # Mark the start time for user-notification\n",
    "        \n",
    "    # Loop through all images, calculate the hash and store it and filename in two lists\n",
    "    name_list, hash_list = [], []\n",
    "    for count, image in enumerate(image_list):\n",
    "        name_list.append(image)\n",
    "        try:\n",
    "            hash_val = imagehash.average_hash(Image.open(image))\n",
    "        except OSError:\n",
    "            print (\"Delete {}\".format(image))\n",
    "            hash_val = 0\n",
    "            \n",
    "        hash_list.append(hash_val)\n",
    "        if count % progress_report_frequency == 0 and verbose:\n",
    "            print (\"Hashing image #{}, {} hashes to go.\".format(count, len(image_list) - count))\n",
    "    \n",
    "    if verbose:\n",
    "        print (\"\\nFinished hashing {} images. Starting comparisons.\".format(len(image_list)))\n",
    "    \n",
    "    # Create a DataFrame for managing the hash comparisons and results\n",
    "    df = pd.DataFrame(np.transpose([name_list, hash_list]), columns=[\"File\", \"Hash\"])\n",
    "    df[\"Duplicates\"] = \"\" # Create an empty (for now) DataFrame column\n",
    "    df['DupeStr'] = '' # Create an empty column that will house the string-converted array of duplicates\n",
    "    # Loop through all rows of the DataFrame, computing the difference in hashes between all\n",
    "    for row_num, row in df.iterrows():\n",
    "        # Store all file names whose hash is below the threshold in that row's Duplicate column\n",
    "        df.at[row_num, \"Duplicates\"] = df[(~df['DupeStr'].str.contains(row['File']).any()) & (abs(df[\"Hash\"] - row[\"Hash\"]) < hash_threshold) & (df[\"File\"] != row[\"File\"])][\"File\"].values\n",
    "        df.at[row_num, 'DupeStr'] = ' '.join(map(str, row['Duplicates']))\n",
    "    \n",
    "        if row_num % progress_report_frequency == 0 and verbose:\n",
    "            print (\"Computed hash differences on {} images. {} comparisons to go.\".format(row_num+1, num_comparisons(image_list[row_num:])))\n",
    "    \n",
    "    # Create the duplicated entries folder that has aliases to each duplicated file\n",
    "    create_duplicate_aliases(path, df)\n",
    "    \n",
    "    # If applicable, notify the user of how long the operations took\n",
    "    if verbose:\n",
    "        print (\"Took {:.2} minutes\".format((time.time() - start_time) / 60.0))\n",
    "        \n",
    "    # Return the DataFrame just for display purposes\n",
    "    return df[df['Duplicates'].astype(str) != '[]'][['File', 'Duplicates']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a `/Duplicates/` folder that contains aliases to each duplicated picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_duplicate_aliases(path, df):\n",
    "    # Filter the DataFrame to ignore all entries without duplicates\n",
    "    df = df[df[\"Duplicates\"].astype(str) != '[]'][[\"File\", \"Duplicates\"]].reset_index(drop=True)\n",
    "    \n",
    "    # Return if no duplicates are found\n",
    "    if len(df) == 0:\n",
    "        return\n",
    "    \n",
    "    # Create the folder where duplicate will be placed\n",
    "    try:\n",
    "        os.mkdir(os.path.join(path, \"Duplicates\"))\n",
    "    except:\n",
    "        print (\"/Duplicates/ folder already exists.\")\n",
    "        \n",
    "    # Loop through all rows in the duplicate entries - for each row, create a \n",
    "    for row_num, row in df.iterrows():\n",
    "        # Create a numbered folder to contain aliases to all matched duplicates\n",
    "        os.mkdir(os.path.join(path, 'Duplicates', str(row_num)))\n",
    "        # Create the alias to the source file that there are duplicates of\n",
    "        os.symlink(row['File'], os.path.join(path, 'Duplicates', str(row_num), \"{}.{}\".format(row['File'][len(path):].split('/')[0], row['File'].split('.')[-1])))\n",
    "        # Loop through all found duplicates and create aliases for each one\n",
    "        for dupe_num, dupe in enumerate(row['Duplicates']):\n",
    "            os.symlink(dupe, os.path.join(path, 'Duplicates', str(row_num), '{} ({}).{}'.format(dupe[len(path):].split('/')[0], dupe_num, dupe.split(\".\")[-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific function to rename the `/grouped/` subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the /Grouped/ subfolder\n",
    "def rename_grouped(path):\n",
    "    image_list = get_image_list(path)\n",
    "    originalLen = len(image_list)\n",
    "    if not os.path.isdir(path + \"new/\"): # Make the /new/ subfolder if it doesn't exist\n",
    "        os.makedirs(path + \"new/\")\n",
    "        print (\"Created /new/ folder\")\n",
    "    adjust_val = 0\n",
    "    for count, image in enumerate(image_list):\n",
    "        group_count = image.split(\"-\")[0] # Grab the group count of this image\n",
    "        # group_list is the list of all image in the same group\n",
    "        group_list = [img for img in image_list if img.split(\"-\")[0] == group_count]\n",
    "         # If the subgroup of this image has already been renamed, adjust the count accordingly\n",
    "        if len(group_list) == 0:\n",
    "            adjust_val += 1\n",
    "        # Loop through all images of this same subgroup\n",
    "        for sub_count, sub_image in enumerate(group_list):\n",
    "            if image.lower().endswith(\".jpeg\"): # New name for longer file names\n",
    "                new_name = \"{}new/{}-{}{}\".format(path, count+1-adjust_val, sub_count+1, image[-5:])\n",
    "            else:\n",
    "                new_name = \"{}new/{}-{}{}\".format(path, count+1-adjust_val, sub_count+1, image[-4:])\n",
    "            os.rename(path + sub_image, new_name) # Move to the /new/ folder (with the new name)\n",
    "            time.sleep(0.08) # Sleep between each command to avoid losing files\n",
    "            \n",
    "        image_list = get_image_list(path) # Reset the image list now that some have been moved\n",
    "        \n",
    "    # Move the images back from /Grouped/new/ to /Grouped/\n",
    "    for image in os.listdir(path + \"new/\"):\n",
    "        os.rename(path + \"new/\" + image, path + image)\n",
    "        time.sleep(0.08)\n",
    "        \n",
    "    os.rmdir(path + \"new\") # Delete /path/new/ subfolder\n",
    "    print (\"{} images renamed.\".format(originalLen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to rename all functions in a given directory (1, 2, 3...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_all(path, verbose=True):\n",
    "    if path.endswith(\"Grouped/\") or path.endswith(\"Known/\"): # Prevent accidentally renaming the grouped folder\n",
    "        rename_grouped(path)\n",
    "        return\n",
    "    \n",
    "    ## Move Images\n",
    "    if verbose:\n",
    "        print ('Moving images.')\n",
    "    # Make the /temp/ subfolder if it doesn't exist\n",
    "    if not os.path.isdir(os.path.join(path, 'temp')): \n",
    "        os.makedirs(os.path.join(path, 'temp'))\n",
    "        if verbose:\n",
    "            print (\"Created /temp/ folder.\")\n",
    "        \n",
    "    # Move all the images to the /temp/ subfolder\n",
    "    image_list = get_image_list(path, move=True, videos=False)\n",
    "    for count, image in enumerate(image_list):\n",
    "        os.rename(image, \"{}/{}.{}\".format(os.path.join(path, 'temp'), count+1, image.split('.')[-1]))\n",
    "        time.sleep(0.10)\n",
    "        \n",
    "    # Move all the images back from /path/temp/ to /path/\n",
    "    for image in get_image_list(os.path.join(path, 'temp'), move=True, videos=False):\n",
    "        os.rename(image, os.path.join(path, image.split('/temp/')[-1]))\n",
    "        time.sleep(0.10)\n",
    "\n",
    "    ## Move Videos\n",
    "    if verbose:\n",
    "        print ('Moving videos.')\n",
    "    # Make the /Videos/ subfolder if it doesn't exist\n",
    "    if not os.path.isdir(os.path.join(path, 'Videos')):\n",
    "        os.makedirs(os.path.join(path, 'Videos'))\n",
    "        if verbose:\n",
    "            print ('Created /Videos/ folder.')\n",
    "            \n",
    "    # Move all the videos to the /temp/ subfolder\n",
    "    for count, image in enumerate(get_image_list(path, move=True, videos=True)):\n",
    "        os.rename(image, \"{}/V{}.{}\".format(os.path.join(path, 'temp'), count+1, image.split('.')[-1]))\n",
    "        time.sleep(0.15)\n",
    "    \n",
    "    # Move videos back from /path/temp/ to /path/Videos/\n",
    "    for image in get_image_list(os.path.join(path, 'temp'), move=True, videos=True):\n",
    "        os.rename(image, os.path.join(path, 'Videos', image.split('/temp/')[-1]))\n",
    "        time.sleep(0.15)\n",
    "        \n",
    "    # Delete the /temp/ directory\n",
    "    os.rmdir(os.path.join(path, 'temp')) # Delete /path/new/ subfolder\n",
    "    if verbose:\n",
    "        print (\"Deleting temporary subfolder.\")\n",
    "        \n",
    "    # If there were no videos, delete the /Videos/ subfolder\n",
    "    if len(get_image_list(os.path.join(path, 'Videos'), move=True, videos=True)) == 0:\n",
    "        os.rmdir(os.path.join(path, 'Videos'))\n",
    "        print (\"No videos found - deleting subfolder.\")\n",
    "        \n",
    "    if verbose:\n",
    "        print (\"{} items renamed.\".format(len(get_image_list(path))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ace50ed7ddc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mrename_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_rows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'display.max_colwidth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentify_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "image_path = '/Volumes/Seagate Backup Plus Drive/Miscellaneous/Google Drive'\n",
    "image_path += '/'\n",
    "ignore_list = ['2018', '2019']\n",
    "rename = False\n",
    "\n",
    "if rename:\n",
    "    rename_all(image_path, verbose=True)\n",
    "else:\n",
    "    with pd.option_context('display.max_rows', 1000, 'display.max_colwidth', 10000):\n",
    "        display(identify_duplicates(image_path, ignore_list, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
