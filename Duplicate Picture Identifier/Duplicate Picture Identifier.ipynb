{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicate Picture Identifier\n",
    "##### by Collin Heist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `FileSorter` Class\n",
    "\n",
    "### Initialization Parameters\n",
    "- `primary_dir`: _String_\n",
    " - This is the primarily directory where all file sorting should take place relative to.\n",
    " - This directory should be empty on its own, but contain the relevant subfolders for sorting.\n",
    "- `sort`: _String, optional_\n",
    " - Specific directory (relative to `primary_dir` where the to-be-sorted files are found.\n",
    " - If unspecified, defaults to `/primary_dir/Sort/`.\n",
    "- `named`: _String, optional_\n",
    " - Specified directory where all _named_ (either by filename or username OCR) files will attempt to be placed.\n",
    " - If unspecified, defaults to `/primary_dir/Named/`.\n",
    " - This should contain subfolders corresponding to each named instance (trip, person, etc.).\n",
    " - Within each named subfolder there should be a text document containing the label to match unsorted files to.\n",
    " - An example is `/primary_dir/Named/Trip to Chicago 2020/label.txt` that says: `@chicago2020` - thus all files named `chicago2020-*` will be placed within this subfolder.\n",
    "- `unnamed`: _String, optional_\n",
    " - Specified directory where all unnamed (files labelled as `Unnamed-*.*`) will be placed.\n",
    " - If unspecified, defaults to `/primary_dir/Unnamed/`.\n",
    "- `tt`: _String, optional_\n",
    " - Specified directory where all named (via filename, not OCR) videos are placed.\n",
    " - If unspecified, defaults to `/primary_dir/TT/`.\n",
    " - The purpose if this is to separate named _videos_ from pictures, primarily because I cannot perform OCR on images (and thus they're hard to map).\n",
    "- `hash_threshold`: _Integer, optional_\n",
    " - This is the maximum difference between hashes that will be counted as a duplicate (with regards to duplicate identifcation).\n",
    " - If unspecified, defaults to `5`.\n",
    " - A value between 0 and 7 seem reasonable, with 0 leading to a lot of missed duplicates, and 7 giving a lot of false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typical File Structure\n",
    "\n",
    "Files from `/Sort/` are placed into their appropriate directory within `/Named/`, or `/Unnamed/` when `.sort()` is called.\n",
    "\n",
    "    Primary Directory\n",
    "    ├── Named\n",
    "    |   ├── Named Folder 1\n",
    "    |   |   └── mapping.txt\n",
    "    |   └── Named Folder 2\n",
    "    |       └── mapping.txt\n",
    "    ├── Sort \n",
    "    |   ├── random_image.jpeg\n",
    "    |   ├── named_image1-1.png\n",
    "    |   ├── named_image1-2.png\n",
    "    |   ├── named_image2-1.png\n",
    "    |   ├── named_image2-2.png\n",
    "    |   ├── Ungrouped-1.heic\n",
    "    |   └── ...\n",
    "    ├── TT\n",
    "    ├── Unnamed\n",
    "    |   └── Ungrouped\n",
    "    |       ├── 1.jpeg\n",
    "    |       ├── 2.jpg\n",
    "    |       └── ...\n",
    "    └──"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import imagehash               # Hashing images for duplicate identification\n",
    "import os                      # File management (directories, files, etc.)\n",
    "import time                    # Time delays between file movements\n",
    "import pandas as pd            # Dataframe (how all data is parsed)\n",
    "from tqdm.notebook import tqdm # Progress Bars on sorting functionality\n",
    "import re                      # Regex searches on filenames and username identification\n",
    "import cv2                     # More optical character recognition\n",
    "import pytesseract             # Optical Character Recognition (OCR) for usernames\n",
    "import numpy as np             # Array manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileSorter():\n",
    "    video_extensions = ('.mov', '.mp4', '.gif', '.webm', '.mkv')\n",
    "    image_extensions = ('.jpg', '.jpeg', '.png', '.heic')\n",
    "    dupe_extensions = (\".jpg\", \".jpeg\", \".png\")\n",
    "    \n",
    "    format_string = '{desc}: {percentage:05.2f}%{bar}{n_fmt}/{total_fmt} [{elapsed}, {rate:05.2f}]'\n",
    "    \n",
    "    sort_regex = re.compile('^.*-\\d+.') # Match named files [username-number.extension]\n",
    "    username_regex = re.compile('(@|\\/[^u][^\\/])\\S+') # Match @username and /u/username\n",
    "    \n",
    "    ocr_tesseract_config = '--psm 6 -c tessedit_char_whitelist=abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789._' # Valid characters in usernames\n",
    "    box_threshold = 250 # 0 (black) - 255 (white) for average of the 92 pixels being looked at\n",
    "    item_move_delay = 0.15 # How many seconds to wait between calls of os.rename()\n",
    "    \n",
    "    def __init__(self, primary_dir, sort='Sort', named='Named', unnamed='Unnamed', tt='TT', hash_threshold=5):\n",
    "        self.dir = primary_dir\n",
    "        self.sort_dir = os.path.join(primary_dir, sort)\n",
    "        self.named_dir = os.path.join(primary_dir, named)\n",
    "        self.ungrouped_dir = os.path.join(primary_dir, unnamed, 'Ungrouped')\n",
    "        self.tt_dir = os.path.join(primary_dir, tt)\n",
    "        self.hash_threshold = hash_threshold\n",
    "        \n",
    "    def __str__(self):\n",
    "        print_str = f'Hash Threshold: {self.hash_threshold}'\n",
    "        return print_str + '{}/\\n - {}/\\n - {}/\\n - {}/'.format(self.dir, self.sort_dir[len(self.dir):], self.named_dir[len(self.dir):], self.tt_dir[len(self.dir):])\n",
    "        \n",
    "    def __repr__(self):\n",
    "        nl, t = '\\n', '    '\n",
    "        return (f'{self.__class__.__name__}({nl}{t}{self.dir!r}, {nl}{t}{self.sort_dir!r}, {nl}{t}{self.named_dir!r},\\\n",
    "                {nl}{t}{self.ungrouped_dir!r}, {nl}{t}{self.tt_dir!r}, {nl}{t}{self.hash_threshold!r}{nl})') \n",
    "    \n",
    "    # Function to sort self.sort_dir to their respsective folders in self.named_dir\n",
    "    def sort(self, sort_named_after=True):\n",
    "        # Get list of all images + videos for moving within this directory\n",
    "        file_list = self.get_images(self.sort_dir) + self.get_videos(self.sort_dir)\n",
    "        username_list = []\n",
    "        \n",
    "        df = pd.DataFrame(columns=['Source', 'S-Source', 'Username', 'Destination', 'S-Destination', 'Extension'])\n",
    "        df['Source'] = file_list\n",
    "        df['S-Source'] = [file[len(self.dir) + 1:] for file in file_list]\n",
    "        df['Extension'] = df['Source'].str.split('.').str[-1].str.lower() # Get the extension of all images\n",
    "        \n",
    "        if len(df) == 0: # If no files are to be sorted\n",
    "            return ('No files in ', str(self.sort_dir))\n",
    "        \n",
    "        # Get the username of all images; either through OCR or looking at the filename\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df), desc='Recognizing Usernames', ncols='100%', bar_format=FileSorter.format_string):\n",
    "            image = row['Source'][len(self.sort_dir) + 1:]\n",
    "            match = FileSorter.sort_regex.match(image)\n",
    "            if match == None and ('.' + row['Extension']) in FileSorter.image_extensions:\n",
    "                username_list.append(self.username_ocr(row['Source'])) # If the file isn't prenamed, perform OCR\n",
    "            elif match == None and ('.' + row['Extension']) in FileSorter.video_extensions: # All unnamed videos\n",
    "                username_list.append('No Username Found')\n",
    "            else:\n",
    "                username_list.append(image[:match.group().rfind('-')]) # If the file is prenamed\n",
    "\n",
    "        df['Username'] = username_list # Assign found username to each image\n",
    "        df = self.__find_destinations(df) # Find corresponding destination files for all identified socials\n",
    "        df['S-Destination'] = df['Destination'].str.slice(len(self.dir) + 1) # Shorten filepath\n",
    "        df.loc[df['Destination'] == 'No Destination Found', 'S-Destination'] = 'No Destination Found'\n",
    "        \n",
    "        # Get the DataFrame of the files that have a valid, sorted destination\n",
    "        move_df = df[df['Destination'] != 'No Destination Found']\n",
    "        if len(move_df) != 0:\n",
    "            for _, row in tqdm(move_df.iterrows(), total=len(move_df), desc='Moving Socials', ncols='100%', bar_format=FileSorter.format_string):\n",
    "                self.move_file(row['Source'], row['Destination'], row['Extension'], is_video=False)\n",
    "                time.sleep(FileSorter.item_move_delay)\n",
    "            \n",
    "        # Move all username'd, but unsortable files\n",
    "        rename_df = df[(df['Username'] != 'No Username Found') & (df['Destination'] == 'No Destination Found')]\n",
    "        if len(rename_df) != 0:\n",
    "            usernames = rename_df['Username'].unique()\n",
    "            for username in tqdm(usernames, unit='Usernames', desc='Renaming Identified Files', ncols='100%', bar_format=FileSorter.format_string):\n",
    "                self.__rename_unsorted_username(df[df['Username'] == username])\n",
    "                \n",
    "        # Now sort all sub-folders of self.named_dir\n",
    "        if sort_named_after:\n",
    "            self.sort_all_named()\n",
    "        \n",
    "        return df[['S-Source', 'Username', 'S-Destination']]\n",
    "    \n",
    "    # Function to go through all items of self.named_dir and sort them\n",
    "    def sort_all_named(self):\n",
    "        all_folders = self.get_folders(self.named_dir, recursion=True)\n",
    "        for folder in tqdm(all_folders, desc='Sorting Named Folders', ncols='100%', bar_format=FileSorter.format_string):\n",
    "            if not self.check_if_sorted(folder): # Only sort if unsorted already\n",
    "                self.rename_directory(folder)\n",
    "\n",
    "    # Function to rename all files of a given username that were not able to be placed in self.named_dir\n",
    "    def __rename_unsorted_username(self, df):\n",
    "        # If all values are videos, then move to self.tt directory instead, otherwise self.sort_dir\n",
    "        dest_dir = self.tt_dir if ('.' + df['Extension']).isin(FileSorter.video_extensions).all() else self.sort_dir \n",
    "        item_number = 1\n",
    "        for _, row in df.iterrows():\n",
    "            # While the destination filename exists, skip over that file\n",
    "            while os.path.exists(os.path.join(dest_dir, f\"{row['Username']}-{item_number}.{row['Extension']}\")):\n",
    "                item_number += 1\n",
    "                \n",
    "            if os.path.exists(row['Source']):\n",
    "                os.rename(row['Source'], os.path.join(dest_dir, f\"{row['Username']}-{item_number}.{row['Extension']}\"))\n",
    "                time.sleep(FileSorter.item_move_delay)\n",
    "                item_number += 1\n",
    "        \n",
    "    # Function to move file.extension from source to destination folder, adds V\n",
    "    def move_file(self, source, destination, extension, is_video=False):\n",
    "        item_number = 1\n",
    "        while os.path.exists(os.path.join(destination, f'{item_number}.{extension}')):\n",
    "            item_number += 1\n",
    "            \n",
    "        new_name = f\"{'Videos/' if is_video else ''}{'V' if is_video else ''}{item_number}.{extension}\"\n",
    "        try:\n",
    "            os.rename(source, os.path.join(destination, new_name))\n",
    "        except FileNotFoundError:\n",
    "            os.mkdir(os.path.join(destination, 'Videos')) # Create /Videos/ subfolder if it didn't exist\n",
    "            os.rename(source, os.path.join(destination, new_name)) # Move file now that /Videos/ folder exists\n",
    "    \n",
    "    # Find the destination folders for all socials specified within the passed DataFrame (based on matching usernames)\n",
    "    def __find_destinations(self, df):\n",
    "        named_usernames = df['Username'].unique() # Get unique list of all identified usernames\n",
    "        text_files = self.get_text_files(self.named_dir)\n",
    "        text_usernames = [self.get_usernames(text_file) for text_file in text_files]\n",
    "        \n",
    "        # Go through all the unique socials in the sorting group\n",
    "        for username in named_usernames: \n",
    "            matching_file = 'No Destination Found/'\n",
    "            \n",
    "            if username.lower() == 'ungrouped':\n",
    "                matching_file = self.ungrouped_dir + '/'\n",
    "            elif username.lower() == 'grouped':\n",
    "                matching_file = 'No Destination Found/'\n",
    "            else:\n",
    "                for file, username_list in zip(text_files, text_usernames):\n",
    "                    if username.lower() in username_list:\n",
    "                        matching_file = file\n",
    "                        break\n",
    "                    \n",
    "            df.loc[df['Username'] == username, 'Destination'] = matching_file[:matching_file.rfind('/')]\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    # Get the usernames listed within a given text file\n",
    "    def get_usernames(self, text_file):\n",
    "        with open(text_file, 'r') as file:\n",
    "            try:\n",
    "                return [FileSorter.username_regex.search(word).group()[1:].lower() for line in file.readlines() for word in line.split(',')]\n",
    "            except AttributeError: # If .group() fails (meaning no match on the regex), then print the file and return invalid\n",
    "                print (f'Invalid username entry within {text_file}')\n",
    "                return ['---invalid_username---']\n",
    "            \n",
    "    # Perform OCR on an image specified at path - crops the image based on where the identified social tag is\n",
    "    def username_ocr(self, path):\n",
    "        image = ImageOps.invert(Image.open(path).convert('L')) # Open, invert, convert to black and white\n",
    "        image_arr = np.array(image)\n",
    "        image_width, image_height = image.size\n",
    "        if image_width < 92 or image_height < 92: \n",
    "            return \"No Username Found\" # If the image is too small for a valid username tag, return\n",
    "        \n",
    "        # Determine which corner of the image the label is in by looking at sections of 92 pixels in each corner\n",
    "        is_bottom_left = np.average(image_arr[-92:, 1:4]) > FileSorter.box_threshold and np.average(image_arr[-5:-2, :92]) > FileSorter.box_threshold\n",
    "        is_top_left = np.average(image_arr[:92, 1:4]) > FileSorter.box_threshold and np.average(image_arr[1:4, :92]) > FileSorter.box_threshold\n",
    "        is_bottom_right = np.average(image_arr[-92:, -5:-2]) > FileSorter.box_threshold and np.average(image_arr[-5:-2, -92:]) > FileSorter.box_threshold\n",
    "        is_top_right = np.average(image_arr[:92, -5:-2]) > FileSorter.box_threshold and np.average(image_arr[1:4, -92:]) > FileSorter.box_threshold\n",
    "        if np.sum([is_bottom_left, is_top_left, is_bottom_right, is_top_right]) != 1:\n",
    "            return 'No Username Found' # If the number of boxes found != 1, return\n",
    "        \n",
    "        # Find width of the label field by counting the number of black (white) pixels\n",
    "        row = 3 if is_top_left or is_top_right else -4         # Which pixel row of the image to count along\n",
    "        direction = 1 if is_bottom_left or is_top_left else -1 # Which direction to iterate through the image in\n",
    "        column = 3 if is_bottom_left or is_top_left else -4    # Which pixel column of the image to count along\n",
    "        box_width = 0\n",
    "        moving_window = [image_arr[row, column], image_arr[row, column + direction], image_arr[row, column + 2 * direction]]\n",
    "        while np.average(moving_window) > FileSorter.box_threshold and box_width < image_width - 5:\n",
    "            moving_window = [image_arr[row, column], image_arr[row, column + direction], image_arr[row, column + 2 * direction]]\n",
    "            column += direction\n",
    "            box_width += 1\n",
    "        \n",
    "        # Crop the image, perform OCR and return the result\n",
    "        crop_x1 = 92 if is_bottom_left or is_top_left else image_width - box_width + 92\n",
    "        crop_y1 = 0 if is_top_left or is_top_right else image_height - 92\n",
    "        crop_x2 = box_width if is_bottom_left or is_top_left else image_width\n",
    "        crop_y2 = 92 if is_top_left or is_top_right else image_height\n",
    "        if crop_x1 > image_width or crop_x2 > image_width or crop_y1 > image_height or crop_y2 > image_height or crop_x2 < crop_x1 or crop_y2 < crop_y1:\n",
    "            return 'No Username Found' # If the computed crop positions are out of bounds, return\n",
    "        \n",
    "        # Provided no errors occurred, parse the cropped image for a username and return it\n",
    "        return pytesseract.image_to_string(image.crop((crop_x1, crop_y1, crop_x2, crop_y2)), lang='eng', config=FileSorter.ocr_tesseract_config)\n",
    "    \n",
    "    # Function to check if the contents of a  given path are sorted or not \n",
    "    def check_if_sorted(self, path, is_videos=False):\n",
    "        # Verify if all images are sorted\n",
    "        contents = self.get_videos(path, False) if is_videos else self.get_images(path, False)\n",
    "        short_contents = [file[len(path):] for file in contents]\n",
    "        num_elements = len(short_contents)\n",
    "        try:\n",
    "            # Try and cast pre-extension filename as integers, sort them, and compare to proper names\n",
    "            content_numbers = np.sort(np.array([file[1 + int(is_videos):file.rfind('.')] for file in short_contents]).astype(int))\n",
    "            correct_numbers = np.arange(1, num_elements + 1)\n",
    "            # If there are >0 inequalities in the element names when compared to correct names, they're unsorted\n",
    "            if np.sum(content_numbers != correct_numbers) == 0:\n",
    "                if os.path.exists(os.path.join(path, 'Videos')): # If /Videos/ exists, check it is sorted as well\n",
    "                    return self.check_if_sorted(os.path.join(path, 'Videos'), True)\n",
    "                else: # If no ValueError was thrown and video's didn't exist / was checked, folder is Sorted\n",
    "                    return True\n",
    "            else:\n",
    "                return False\n",
    "        except ValueError: # Value error occurs trying to cast np array .astype(int) - meaning incorrect names\n",
    "            return False\n",
    "            \n",
    "    # Function to rename all files of a given path - /path/1, /path/2, etc. for images, /path/Videos/V1, ... for Videos\n",
    "    def rename_directory(self, path):\n",
    "        # Make the /temp/ subfolder if it doesn't exist\n",
    "        os.makedirs(os.path.join(path, 'temp'), exist_ok=True)\n",
    "\n",
    "        # Move all the images to the /temp/ subfolder\n",
    "        image_list = self.get_images(path)\n",
    "        for count, image in enumerate(image_list):\n",
    "            os.rename(image, f\"{os.path.join(path, 'temp', str(count+1))}.{image.split('.')[-1]}\")\n",
    "            time.sleep(FileSorter.item_move_delay)\n",
    "\n",
    "        # Move all the images back from /path/temp/ to /path/\n",
    "        for image in self.get_images(os.path.join(path, 'temp')):\n",
    "            os.rename(image, os.path.join(path, image.split('/temp/')[-1]))\n",
    "            time.sleep(FileSorter.item_move_delay)\n",
    "\n",
    "        ## Move Videos\n",
    "        # Make the /Videos/ subfolder if it doesn't exist\n",
    "        os.makedirs(os.path.join(path, 'Videos'), exist_ok=True)\n",
    "\n",
    "        do_recurse_videos = False if path.endswith('-Famous') else True\n",
    "        video_list = self.get_videos(path, recursion=do_recurse_videos)\n",
    "        if len(video_list) != 0:\n",
    "            # Move all the videos to the /temp/ subfolder\n",
    "            for count, image in enumerate(video_list):\n",
    "                os.rename(image, f\"{os.path.join(path, 'temp', 'V' + str(count+1))}.{image.split('.')[-1]}\")\n",
    "                time.sleep(FileSorter.item_move_delay)\n",
    "\n",
    "            # Move videos back from /path/temp/ to /path/Videos/\n",
    "            for image in self.get_videos(os.path.join(path, 'temp')):\n",
    "                os.rename(image, os.path.join(path, 'Videos', image.split('/temp/')[-1]))\n",
    "                time.sleep(FileSorter.item_move_delay)\n",
    "\n",
    "        # If there were no videos, delete the /Videos/ subfolder\n",
    "        if len(self.get_videos(os.path.join(path, 'Videos'))) == 0:\n",
    "            os.rmdir(os.path.join(path, 'Videos'))\n",
    "\n",
    "        # Delete the /temp/ directory\n",
    "        os.rmdir(os.path.join(path, 'temp')) # Delete /path/new/ subfolder\n",
    "        \n",
    "    def get_folders(self, path, recursion=True, ignore_list=['Videos']):\n",
    "        list_of_files = os.listdir(path)\n",
    "        all_folders = []\n",
    "        \n",
    "        for entry in list_of_files:\n",
    "            full_path = os.path.join(path, entry)\n",
    "            if os.path.isdir(full_path) and entry not in ignore_list:\n",
    "                all_folders.append(full_path)\n",
    "                if recursion:\n",
    "                    all_folders = all_folders + self.get_folders(full_path, recursion)\n",
    "                    \n",
    "        return all_folders\n",
    "    \n",
    "    # Function to get all text files within a given path and return a list of their directories\n",
    "    def get_text_files(self, path, recursion=True):\n",
    "        list_of_files = os.listdir(path)\n",
    "        all_files = []\n",
    "        \n",
    "        for entry in list_of_files:\n",
    "            full_path = os.path.join(path, entry)\n",
    "            if os.path.isdir(full_path) and recursion:\n",
    "                all_files = all_files + self.get_text_files(full_path, recursion)\n",
    "            else:\n",
    "                all_files.append(full_path)\n",
    "                \n",
    "        return [file for file in all_files if file.lower().endswith('.txt')]\n",
    "    \n",
    "    def get_videos(self, path, recursion=False, ignore_list=['Duplicates']):\n",
    "        return self.__get_file_list(path, move=True, videos=True, recursion=recursion, ignore_list=ignore_list)\n",
    "    \n",
    "    def get_images(self, path, recursion=False, ignore_list=['Duplicates']):\n",
    "        return self.__get_file_list(path, move=True, videos=False, recursion=recursion, ignore_list=ignore_list)\n",
    "    \n",
    "    def get_dupe_images(self, path, recursion=True, ignore_list=['Duplicates']):\n",
    "        return self.__get_file_list(path, move=False, recursion=recursion, ignore_list=ignore_list)\n",
    "    \n",
    "    # Function to get all images at a given path (returns different files based on move, videos, recursion)\n",
    "    def __get_file_list(self, path, move=True, videos=False, recursion=True, ignore_list=['Duplicates']):\n",
    "        list_of_files = os.listdir(path) # Get a list of all files in the current directory\n",
    "        all_files = []\n",
    "        \n",
    "        for entry in list_of_files:\n",
    "            full_path = os.path.join(path, entry)\n",
    "            # If entry is a directory then get the list of files in this directory \n",
    "            if os.path.isdir(full_path) and entry not in ignore_list and recursion:\n",
    "                all_files = all_files + self.__get_file_list(full_path, move, videos, recursion, ignore_list)\n",
    "            else:\n",
    "                all_files.append(full_path)\n",
    "                \n",
    "        if move == False:\n",
    "            return [image for image in all_files if image.lower().endswith(FileSorter.dupe_extensions)]\n",
    "        elif move == True and videos == False:\n",
    "            return [image for image in all_files if image.lower().endswith(FileSorter.image_extensions)]\n",
    "        elif move == True and videos == True:\n",
    "            return [image for image in all_files if image.lower().endswith(FileSorter.video_extensions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a838e8e06147dfb4c08d219aff8ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Recognizing Usernames', layout=Layout(flex='2'), max=379.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8064021e8c1d4f5980b6d53ad1cadcb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Moving Socials', layout=Layout(flex='2'), max=97.0, style…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556a5713e8bd45139c372cc380e205d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Renaming Identified Files', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33446c92177840c09b107db16044e1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Sorting Named Folders', layout=Layout(flex='2'), max=386.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fs = FileSorter('/Volumes/Seagate Backup Plus Drive/Miscellaneous/Google Drive', tt='TikTok')\n",
    "sort_df = fs.sort(sort_named_after=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_duplicates(path, ignore_list=[None], verbose=True):\n",
    "    image_list = get_image_list(path, ignore_list=ignore_list, move=False)\n",
    "    if verbose:\n",
    "        print (\"{} images, requiring {} comparisons\".format(len(image_list), num_comparisons(image_list)))\n",
    "        print (\"This should take about {} minutes\".format(int(time_per_compare * num_comparisons(image_list) / 60.0)))\n",
    "        start_time = time.time() # Mark the start time for user-notification\n",
    "        \n",
    "    # Loop through all images, calculate the hash and store it and filename in two lists\n",
    "    name_list, hash_list = [], []\n",
    "    time.sleep(0.25)\n",
    "    bar_format_string = '{desc}: {percentage:05.2f}%{bar}{n_fmt}/{total_fmt} [{elapsed}, {rate:05.2f} {unit}/s]'\n",
    "    for image in tqdm(image_list, unit='hashes', desc='Image Hashing', ncols='100%', bar_format=bar_format_string):\n",
    "        try:\n",
    "            hash_val = imagehash.average_hash(Image.open(image))\n",
    "        except OSError:\n",
    "            print (\"Delete {}\".format(image))\n",
    "            hash_val = 0\n",
    "            \n",
    "        name_list.append(image)\n",
    "        hash_list.append(hash_val)\n",
    "    \n",
    "    # Create a DataFrame for managing the hash comparisons and results\n",
    "    df = pd.DataFrame(np.transpose([name_list, hash_list]), columns=[\"File\", \"Hash\"])\n",
    "    df[\"Duplicates\"] = \"\" # Create an empty (for now) DataFrame column\n",
    "    df['DupeStr'] = '' # Create an empty column that will house the string-converted array of duplicates\n",
    "    \n",
    "    # Loop through all rows of the DataFrame, computing the difference in hashes between all\n",
    "    for row_num, row in tqdm(df.iterrows(), total=len(df), unit='comparisons', desc='Hash Comparison', ncols='100%', bar_format=bar_format_string):\n",
    "        # Store all file names whose hash is below the threshold in that row's Duplicate column\n",
    "        df.at[row_num, \"Duplicates\"] = df[(~df['DupeStr'].str.contains(row['File']).any()) & (abs(df[\"Hash\"] - row[\"Hash\"]) < hash_threshold) & (df[\"File\"] != row[\"File\"])][\"File\"].values\n",
    "        df.at[row_num, 'DupeStr'] = ' '.join(map(str, row['Duplicates']))\n",
    "    \n",
    "    # Create the duplicated entries folder that has aliases to each duplicated file\n",
    "    create_duplicate_aliases(path, df)\n",
    "    \n",
    "    # If applicable, notify the user of how long the operations took\n",
    "    if verbose:\n",
    "        print (\"Took {:.2} minutes\".format((time.time() - start_time) / 60.0))\n",
    "        \n",
    "    # Return the DataFrame just for display purposes\n",
    "    return df[df['Duplicates'].astype(str) != '[]'][['File', 'Duplicates']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_per_compare = 1e-4\n",
    "hash_threshold = 5\n",
    "progress_report_frequency = 50\n",
    "video_extensions = ('.mov', '.mp4', '.gif', '.webm', '.mkv')\n",
    "image_extensions = ('.jpg', '.jpeg', '.png', '.heic')\n",
    "dupe_extensions = (\".jpg\", \".jpeg\", \".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get the image list\n",
    "This function takes a given directory and returns all files that fit either the move or duplicate extension criteria, as set by the value of `move`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to check all images in a given path for duplicates\n",
    "This is the coup de grâce; all images in the provided path are compared, duplicates are identified and a convenient `DataFrame` is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_duplicates(path, ignore_list=[None], verbose=True):\n",
    "    image_list = get_image_list(path, ignore_list=ignore_list, move=False)\n",
    "    if verbose:\n",
    "        print (\"{} images, requiring {} comparisons\".format(len(image_list), num_comparisons(image_list)))\n",
    "        print (\"This should take about {} minutes\".format(int(time_per_compare * num_comparisons(image_list) / 60.0)))\n",
    "        start_time = time.time() # Mark the start time for user-notification\n",
    "        \n",
    "    # Loop through all images, calculate the hash and store it and filename in two lists\n",
    "    name_list, hash_list = [], []\n",
    "    time.sleep(0.25)\n",
    "    bar_format_string = '{desc}: {percentage:05.2f}%{bar}{n_fmt}/{total_fmt} [{elapsed}, {rate:05.2f} {unit}/s]'\n",
    "    for image in tqdm(image_list, unit='hashes', desc='Image Hashing', ncols='100%', bar_format=bar_format_string):\n",
    "        try:\n",
    "            hash_val = imagehash.average_hash(Image.open(image))\n",
    "        except OSError:\n",
    "            print (\"Delete {}\".format(image))\n",
    "            hash_val = 0\n",
    "            \n",
    "        name_list.append(image)\n",
    "        hash_list.append(hash_val)\n",
    "    \n",
    "    # Create a DataFrame for managing the hash comparisons and results\n",
    "    df = pd.DataFrame(np.transpose([name_list, hash_list]), columns=[\"File\", \"Hash\"])\n",
    "    df[\"Duplicates\"] = \"\" # Create an empty (for now) DataFrame column\n",
    "    df['DupeStr'] = '' # Create an empty column that will house the string-converted array of duplicates\n",
    "    \n",
    "    # Loop through all rows of the DataFrame, computing the difference in hashes between all\n",
    "    for row_num, row in tqdm(df.iterrows(), total=len(df), unit='comparisons', desc='Hash Comparison', ncols='100%', bar_format=bar_format_string):\n",
    "        # Store all file names whose hash is below the threshold in that row's Duplicate column\n",
    "        df.at[row_num, \"Duplicates\"] = df[(~df['DupeStr'].str.contains(row['File']).any()) & (abs(df[\"Hash\"] - row[\"Hash\"]) < hash_threshold) & (df[\"File\"] != row[\"File\"])][\"File\"].values\n",
    "        df.at[row_num, 'DupeStr'] = ' '.join(map(str, row['Duplicates']))\n",
    "    \n",
    "    # Create the duplicated entries folder that has aliases to each duplicated file\n",
    "    create_duplicate_aliases(path, df)\n",
    "    \n",
    "    # If applicable, notify the user of how long the operations took\n",
    "    if verbose:\n",
    "        print (\"Took {:.2} minutes\".format((time.time() - start_time) / 60.0))\n",
    "        \n",
    "    # Return the DataFrame just for display purposes\n",
    "    return df[df['Duplicates'].astype(str) != '[]'][['File', 'Duplicates']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a `/Duplicates/` folder that contains aliases to each duplicated picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_duplicate_aliases(path, df):\n",
    "    # Filter the DataFrame to ignore all entries without duplicates\n",
    "    df = df[df[\"Duplicates\"].astype(str) != '[]'][[\"File\", \"Duplicates\"]].reset_index(drop=True)\n",
    "    \n",
    "    # Return if no duplicates are found\n",
    "    if len(df) == 0:\n",
    "        return\n",
    "    \n",
    "    # Create the folder where duplicate will be placed\n",
    "    try:\n",
    "        os.mkdir(os.path.join(path, \"Duplicates\"))\n",
    "    except:\n",
    "        print (\"/Duplicates/ folder already exists.\")\n",
    "        \n",
    "    # Loop through all rows in the duplicate entries - for each row, create a \n",
    "    for row_num, row in df.iterrows():\n",
    "        # Create a numbered folder to contain aliases to all matched duplicates\n",
    "        os.mkdir(os.path.join(path, 'Duplicates', str(row_num)))\n",
    "        # Create the alias to the source file that there are duplicates of\n",
    "        os.symlink(row['File'], os.path.join(path, 'Duplicates', str(row_num), \"0 - {}, {}.{}\".format(row['File'].split('/')[-2], row['File'].split('/')[-1].split('.')[-2], row['File'].split('.')[-1])))\n",
    "        # Loop through all found duplicates and create aliases for each one\n",
    "        for dupe_num, dupe in enumerate(row['Duplicates']):\n",
    "            os.symlink(dupe, os.path.join(path, 'Duplicates', str(row_num), '{} - {}, {}.{}'.format(dupe_num + 1, dupe.split('/')[-2], dupe.split('/')[-1].split('.')[-2], dupe.split(\".\")[-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific function to rename the `/grouped/` subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the /Grouped/ subfolder\n",
    "def rename_grouped(path):\n",
    "    image_list = get_image_list(path)\n",
    "    originalLen = len(image_list)\n",
    "    if not os.path.isdir(path + \"new/\"): # Make the /new/ subfolder if it doesn't exist\n",
    "        os.makedirs(path + \"new/\")\n",
    "        print (\"Created /new/ folder\")\n",
    "    adjust_val = 0\n",
    "    for count, image in enumerate(image_list):\n",
    "        group_count = image.split(\"-\")[0] # Grab the group count of this image\n",
    "        # group_list is the list of all image in the same group\n",
    "        group_list = [img for img in image_list if img.split(\"-\")[0] == group_count]\n",
    "         # If the subgroup of this image has already been renamed, adjust the count accordingly\n",
    "        if len(group_list) == 0:\n",
    "            adjust_val += 1\n",
    "        # Loop through all images of this same subgroup\n",
    "        for sub_count, sub_image in enumerate(group_list):\n",
    "            if image.lower().endswith(\".jpeg\"): # New name for longer file names\n",
    "                new_name = \"{}new/{}-{}{}\".format(path, count+1-adjust_val, sub_count+1, image[-5:])\n",
    "            else:\n",
    "                new_name = \"{}new/{}-{}{}\".format(path, count+1-adjust_val, sub_count+1, image[-4:])\n",
    "            os.rename(path + sub_image, new_name) # Move to the /new/ folder (with the new name)\n",
    "            time.sleep(0.08) # Sleep between each command to avoid losing files\n",
    "            \n",
    "        image_list = get_image_list(path) # Reset the image list now that some have been moved\n",
    "        \n",
    "    # Move the images back from /Grouped/new/ to /Grouped/\n",
    "    for image in os.listdir(path + \"new/\"):\n",
    "        os.rename(path + \"new/\" + image, path + image)\n",
    "        time.sleep(0.08)\n",
    "        \n",
    "    os.rmdir(path + \"new\") # Delete /path/new/ subfolder\n",
    "    print (\"{} images renamed.\".format(originalLen))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
