{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports required for Machine Learning\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import keras.utils\n",
    "import keras\n",
    "\n",
    "# Reading from table-structured data easily\n",
    "import pandas as pd\n",
    "\n",
    "# Data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Libaries we use for image / data augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from random import randint\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData   = \"/Users/CollinHeist/Dropbox/Machine Learning/data/UI Data Science/trainData.csv\"\n",
    "trainLabels = \"/Users/CollinHeist/Dropbox/Machine Learning/data/UI Data Science/trainLabels.csv\"\n",
    "testData    = \"/Users/CollinHeist/Dropbox/Machine Learning/data/UI Data Science/testData.csv\"\n",
    "correctData = \"/Users/CollinHeist/Dropbox/Machine Learning/data/UI Data Science/correct.csv\"\n",
    "outputPath   = \"/Users/CollinHeist/Dropbox/Machine Learning/data/UI Data Science/output.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a matrix of all the train labels \n",
    "def obtainTrainLabels(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.drop([\"index\"], axis = 1) # Drop the first column\n",
    "    dm = df.as_matrix() # Convert the dataframe to a matrix\n",
    "    \n",
    "    return dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a dataframe of the data in /Path/\n",
    "def obtainTestData(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.drop([\"index\"], axis = 1) # Drop the index column\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a dataframe of the data in /Path/\n",
    "def obtainData(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.drop([\"index\"], axis = 1) # Remove the counting column\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a list of images, each one being a 2D 24x120 array of an expression\n",
    "def formatTestData(dataFrame):\n",
    "    testMatrix = dataFrame.as_matrix() # Convert the dataframe to a Matrix\n",
    "    imageList = [] # A list of all 2D digits - each digit is a 24x24 array\n",
    "    for x in testMatrix:\n",
    "        x = x.reshape(24, 120)\n",
    "        imageList.append(x)\n",
    "        \n",
    "    return imageList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list of 2D arrays for each symbol \n",
    "def formatData(dataFrame):\n",
    "    trainMatrix = dataFrame.as_matrix() # Convert the dataframe to a Matrix\n",
    "    digitList = [] # A list of all 2D digits - each digit is a 24x24 array\n",
    "    for x in trainMatrix:\n",
    "        x = x.reshape(24, 24)\n",
    "        digitList.append(x)\n",
    "        \n",
    "    return digitList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a tuple of three np arrays, one for the image data and one for the image labels\n",
    "# Designed to split all operators (+, -, =) into a separate matrix for a separate model\n",
    "def splitDigitLists(trainMatrix, trainLabels):\n",
    "    symbolList   = []\n",
    "    symbolLabels = []\n",
    "    indexList    = []\n",
    "    for count, label in np.ndenumerate(trainLabels):\n",
    "        if label >= 10: indexList.append(count[0])\n",
    "                        \n",
    "    # Grab the data of all the symbols and put them in lists\n",
    "    for indexes in indexList:\n",
    "        symbolList.append(trainMatrix[indexes])\n",
    "        symbolLabels.append(trainLabels[indexes][0])\n",
    "        \n",
    "    # Make an array of the new training labels to return, to override the old trainLabels\n",
    "    newTrainLabels = []\n",
    "    for i in range(trainLabels.shape[0]):\n",
    "        if i not in indexList:\n",
    "            newTrainLabels.append(trainLabels[i][0])\n",
    "    newLabels = np.array(newTrainLabels).reshape(len(newTrainLabels), 1)\n",
    "    \n",
    "    # Delete the symbol arrays from the trainMatrix\n",
    "    # Flip the order so we can erase the latter elements first - avoid index errors\n",
    "    il = list(reversed(indexList))\n",
    "    for indexes in il:\n",
    "        del trainMatrix[indexes]\n",
    "    \n",
    "    # Convert the lists of labels and image data to numpy arrays\n",
    "    sList   = np.array(symbolList)\n",
    "    sLabels = np.array(symbolLabels)\n",
    "    sLabels = np.subtract(sLabels, 10) # Shift the 10, 11, and 12 values to 0, 1, 2 for one hot encoding\n",
    "            \n",
    "    return (sList, sLabels, newLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a Sequential Convolutional model structured as model.summary()\n",
    "# We use the 'same' padding to avoid major downsampling on the image - allows for a deeper network\n",
    "def createModel(isDigit):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size = (5, 5), strides = (1, 1), activation = \"relu\",\n",
    "                     input_shape = (24, 24, 1)))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "    model.add(Dropout(0.375))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size = (5, 5), activation = \"relu\", padding = \"same\"))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "    model.add(Dropout(0.425))\n",
    "    \n",
    "    model.add(Conv2D(256, kernel_size = (3, 3), activation = \"relu\", padding = \"same\"))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "    model.add(Dropout(0.375))\n",
    "    \n",
    "    if isDigit:\n",
    "        model.add(Conv2D(128, kernel_size = (3, 3), activation = \"relu\", padding = \"same\"))\n",
    "        model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "        model.add(Dropout(0.275))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation = \"relu\"))\n",
    "    model.add(Dropout(0.185))\n",
    "    \n",
    "    # The final layer is either 10 classes or 3 classes, depending on if it's a digit or not\n",
    "    if isDigit:\n",
    "        model.add(Dense(10, activation = \"softmax\"))\n",
    "    else:\n",
    "        model.add(Dense(3, activation = \"softmax\"))\n",
    "\n",
    "    model.compile(loss = keras.losses.categorical_crossentropy,\n",
    "                  optimizer = keras.optimizers.SGD(lr = 0.0075),\n",
    "                  metrics = [\"accuracy\"])\n",
    "    \n",
    "    # print (model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the passed training digits by adding, in the background, a randomly selected digit\n",
    "# also from the training set. This is done to more closely resemble the test-data, which is\n",
    "# artifically altered with background numbers to decrease the accuracy of the model.\n",
    "# this changes approximately probability% of the data to be more complex\n",
    "def augmentImages(trainDigits, probability):\n",
    "    inputLength = len(trainDigits)\n",
    "    for i, image in enumerate(trainDigits):\n",
    "        randIndex = randint(0, inputLength - 1)\n",
    "        # Probabilistically change the data\n",
    "        if randIndex > (inputLength * ((100 - probability) / 100.0)): \n",
    "            # Grab a random image from the training data\n",
    "            randSelect = randint(0, inputLength - 1)\n",
    "            bgImage = trainDigits[randSelect]\n",
    "            \n",
    "            # Reduce the intensity of the background image - Make sure there are no negatives\n",
    "            bgImage = np.subtract(bgImage, (175.0 / 255.0))\n",
    "            bgImage[bgImage < 0] = 0\n",
    "            \n",
    "            # Add the background image to the foreground - to be altered - image\n",
    "            # During this addition, pixel values can become > 1, so process those between [0, 1]\n",
    "            newImage = np.add(bgImage, image)\n",
    "            newImage[newImage > 1] = 1\n",
    "            \n",
    "            # plt.subplot(150)\n",
    "            # plt.imshow(image.reshape(24, 24), cmap = plt.get_cmap('gray'))\n",
    "            trainDigits[i] = newImage\n",
    "            # plt.subplot(151)\n",
    "            # plt.imshow(image.reshape(24, 24), cmap = plt.get_cmap('gray'))\n",
    "            # plt.show()\n",
    "            \n",
    "    return trainDigits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training values\n",
    "dataframe = obtainData(trainData)\n",
    "digitList = formatData(dataframe)\n",
    "digitLabels = obtainTrainLabels(trainLabels)\n",
    "# Split the data into a list of symbols and a list of digits for separate training\n",
    "symbolList, symbolLabels, digitLabels = splitDigitLists(digitList, digitLabels)\n",
    "# Testing values\n",
    "testDF = obtainTestData(testData)\n",
    "testDL = formatTestData(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters and the training data definition(s)\n",
    "# Convert training data to shape (numberSamples, xSize, ySize, numChannels)\n",
    "x_train_digits  = np.asarray(digitList).reshape(len(digitList), 24, 24, 1)\n",
    "x_train_symbols = np.asarray(symbolList).reshape(len(symbolList), 24, 24, 1)\n",
    "# Convert y_train to a one-hot encoded vector for each class - 10 for digits, 3 for symbols\n",
    "y_train_digits  = keras.utils.to_categorical(digitLabels, 10)\n",
    "y_train_symbols = keras.utils.to_categorical(symbolLabels, 3)\n",
    "\n",
    "augmentedProbability = 50\n",
    "x_train_digits = augmentImages(x_train_digits, augmentedProbability)\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "18456/18456 [==============================] - 155s 8ms/step - loss: 1.0633 - acc: 0.3910\n",
      "Epoch 2/20\n",
      "18456/18456 [==============================] - 153s 8ms/step - loss: 0.8524 - acc: 0.6810\n",
      "Epoch 3/20\n",
      "18456/18456 [==============================] - 163s 9ms/step - loss: 0.2981 - acc: 0.9467\n",
      "Epoch 4/20\n",
      "18456/18456 [==============================] - 157s 9ms/step - loss: 0.0706 - acc: 0.9862\n",
      "Epoch 5/20\n",
      "18456/18456 [==============================] - 146s 8ms/step - loss: 0.0336 - acc: 0.9930\n",
      "Epoch 6/20\n",
      "18456/18456 [==============================] - 144s 8ms/step - loss: 0.0214 - acc: 0.9952\n",
      "Epoch 7/20\n",
      "18456/18456 [==============================] - 161s 9ms/step - loss: 0.0143 - acc: 0.9976\n",
      "Epoch 8/20\n",
      "18456/18456 [==============================] - 126s 7ms/step - loss: 0.0113 - acc: 0.9974\n",
      "Epoch 9/20\n",
      "18456/18456 [==============================] - 126s 7ms/step - loss: 0.0097 - acc: 0.9977\n",
      "Epoch 10/20\n",
      "18456/18456 [==============================] - 121s 7ms/step - loss: 0.0080 - acc: 0.9985\n",
      "Epoch 11/20\n",
      "18456/18456 [==============================] - 122s 7ms/step - loss: 0.0062 - acc: 0.9987\n",
      "Epoch 12/20\n",
      "18456/18456 [==============================] - 120s 7ms/step - loss: 0.0058 - acc: 0.9989\n",
      "Epoch 13/20\n",
      "18456/18456 [==============================] - 121s 7ms/step - loss: 0.0056 - acc: 0.9988\n",
      "Epoch 14/20\n",
      "18456/18456 [==============================] - 120s 7ms/step - loss: 0.0044 - acc: 0.9995\n",
      "Epoch 15/20\n",
      "18456/18456 [==============================] - 122s 7ms/step - loss: 0.0040 - acc: 0.9992\n",
      "Epoch 16/20\n",
      "18456/18456 [==============================] - 121s 7ms/step - loss: 0.0037 - acc: 0.9993\n",
      "Epoch 17/20\n",
      "18456/18456 [==============================] - 121s 7ms/step - loss: 0.0035 - acc: 0.9993\n",
      "Epoch 18/20\n",
      "18456/18456 [==============================] - 121s 7ms/step - loss: 0.0029 - acc: 0.9995\n",
      "Epoch 19/20\n",
      "18456/18456 [==============================] - 121s 7ms/step - loss: 0.0030 - acc: 0.9992\n",
      "Epoch 20/20\n",
      "18456/18456 [==============================] - 121s 7ms/step - loss: 0.0024 - acc: 0.9997\n",
      "Epoch 1/75\n",
      "61544/61544 [==============================] - 428s 7ms/step - loss: 2.2993 - acc: 0.1214\n",
      "Epoch 2/75\n",
      "61544/61544 [==============================] - 422s 7ms/step - loss: 2.2776 - acc: 0.1641\n",
      "Epoch 3/75\n",
      "61544/61544 [==============================] - 425s 7ms/step - loss: 1.8088 - acc: 0.3764\n",
      "Epoch 4/75\n",
      "61544/61544 [==============================] - 423s 7ms/step - loss: 0.9434 - acc: 0.6798\n",
      "Epoch 5/75\n",
      "61544/61544 [==============================] - 422s 7ms/step - loss: 0.5988 - acc: 0.8028\n",
      "Epoch 6/75\n",
      "61544/61544 [==============================] - 439s 7ms/step - loss: 0.4358 - acc: 0.8598\n",
      "Epoch 7/75\n",
      "61544/61544 [==============================] - 423s 7ms/step - loss: 0.3534 - acc: 0.8867\n",
      "Epoch 8/75\n",
      "61544/61544 [==============================] - 422s 7ms/step - loss: 0.3038 - acc: 0.9033\n",
      "Epoch 9/75\n",
      "61544/61544 [==============================] - 422s 7ms/step - loss: 0.2681 - acc: 0.9146\n",
      "Epoch 10/75\n",
      "61544/61544 [==============================] - 423s 7ms/step - loss: 0.2440 - acc: 0.9227\n",
      "Epoch 11/75\n",
      "61544/61544 [==============================] - 424s 7ms/step - loss: 0.2225 - acc: 0.9301\n",
      "Epoch 12/75\n",
      "61544/61544 [==============================] - 423s 7ms/step - loss: 0.2093 - acc: 0.9335\n",
      "Epoch 13/75\n",
      "61544/61544 [==============================] - 424s 7ms/step - loss: 0.1962 - acc: 0.9385\n",
      "Epoch 14/75\n",
      "61544/61544 [==============================] - 437s 7ms/step - loss: 0.1905 - acc: 0.9408\n",
      "Epoch 15/75\n",
      "61544/61544 [==============================] - 424s 7ms/step - loss: 0.1789 - acc: 0.9444\n",
      "Epoch 16/75\n",
      "61544/61544 [==============================] - 423s 7ms/step - loss: 0.1674 - acc: 0.9468\n",
      "Epoch 17/75\n",
      "61544/61544 [==============================] - 422s 7ms/step - loss: 0.1611 - acc: 0.9502\n",
      "Epoch 18/75\n",
      "61544/61544 [==============================] - 425s 7ms/step - loss: 0.1511 - acc: 0.9525\n",
      "Epoch 19/75\n",
      "61544/61544 [==============================] - 424s 7ms/step - loss: 0.1474 - acc: 0.9533\n",
      "Epoch 20/75\n",
      "61544/61544 [==============================] - 427s 7ms/step - loss: 0.1430 - acc: 0.9552\n",
      "Epoch 21/75\n",
      "61544/61544 [==============================] - 427s 7ms/step - loss: 0.1387 - acc: 0.9568\n",
      "Epoch 22/75\n",
      "61544/61544 [==============================] - 424s 7ms/step - loss: 0.1324 - acc: 0.9591\n",
      "Epoch 23/75\n",
      "61544/61544 [==============================] - 437s 7ms/step - loss: 0.1316 - acc: 0.9586\n",
      "Epoch 24/75\n",
      "61544/61544 [==============================] - 425s 7ms/step - loss: 0.1242 - acc: 0.9610\n",
      "Epoch 25/75\n",
      "61544/61544 [==============================] - 427s 7ms/step - loss: 0.1260 - acc: 0.9601\n",
      "Epoch 26/75\n",
      "61544/61544 [==============================] - 424s 7ms/step - loss: 0.1186 - acc: 0.9631\n",
      "Epoch 27/75\n",
      "61544/61544 [==============================] - 425s 7ms/step - loss: 0.1177 - acc: 0.9634\n",
      "Epoch 28/75\n",
      "61544/61544 [==============================] - 440s 7ms/step - loss: 0.1134 - acc: 0.9645\n",
      "Epoch 29/75\n",
      "61544/61544 [==============================] - 427s 7ms/step - loss: 0.1130 - acc: 0.9650\n",
      "Epoch 30/75\n",
      "61544/61544 [==============================] - 427s 7ms/step - loss: 0.1069 - acc: 0.9667\n",
      "Epoch 31/75\n",
      "61544/61544 [==============================] - 437s 7ms/step - loss: 0.1063 - acc: 0.9663\n",
      "Epoch 32/75\n",
      "61544/61544 [==============================] - 440s 7ms/step - loss: 0.1036 - acc: 0.9671\n",
      "Epoch 33/75\n",
      "61544/61544 [==============================] - 427s 7ms/step - loss: 0.1017 - acc: 0.9672\n",
      "Epoch 34/75\n",
      "61544/61544 [==============================] - 427s 7ms/step - loss: 0.0999 - acc: 0.9689\n",
      "Epoch 35/75\n",
      "61544/61544 [==============================] - 428s 7ms/step - loss: 0.0984 - acc: 0.9683\n",
      "Epoch 36/75\n",
      "61544/61544 [==============================] - 426s 7ms/step - loss: 0.0966 - acc: 0.9703\n",
      "Epoch 37/75\n",
      "37696/61544 [=================>............] - ETA: 2:45 - loss: 0.0958 - acc: 0.9710"
     ]
    }
   ],
   "source": [
    "# Create our model, and then train it on the training data\n",
    "# Uses the above-defined hyperparameters\n",
    "dModel = createModel(True) # Convolutional network for recognizing digits\n",
    "sModel = createModel(False) # Convolutional network for recognizing symbols\n",
    "\n",
    "# Using an ImageGenerator, modify the data during the training process\n",
    "# The generator randomly zooms in / out, rotates and shifts the image\n",
    "zoomRange = .100   # 0-1 value that represents how much the image can be scaled\n",
    "rotationRange = 24 # Maximum degree value at which to rotate the image\n",
    "shiftVal = .0625    # Maximum percentage at which the image can be shifted\n",
    "datagen = ImageDataGenerator(zoom_range = zoomRange,\n",
    "                             rotation_range = rotationRange, \n",
    "                             width_shift_range = shiftVal, height_shift_range = shiftVal)\n",
    "\n",
    "datagen.fit(x_train_digits)\n",
    "\n",
    "# In-line train the model while generating new data with the ImageGenerator\n",
    "# dHistory = dModel.fit_generator(\n",
    "#            datagen.flow(x_train_digits, y_train_digits,\n",
    "#                         batch_size = batch_size),\n",
    "#            steps_per_epoch = len(x_train_digits) / batch_size,\n",
    "#            epochs = epochs,\n",
    "#            verbose = 1)\n",
    "\n",
    "# Store the history of the training in 'history'\n",
    "sHistory = sModel.fit(x_train_symbols, y_train_symbols,\n",
    "                      batch_size = batch_size, epochs = 20,\n",
    "                      verbose = 1)\n",
    "dHistory = dModel.fit(x_train_digits, y_train_digits,\n",
    "                      batch_size = batch_size, epochs = 75,\n",
    "                      verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evluated.. 0\n",
      "Evluated.. 100\n",
      "Evluated.. 200\n",
      "Evluated.. 300\n",
      "Evluated.. 400\n",
      "Evluated.. 500\n",
      "Evluated.. 600\n",
      "Evluated.. 700\n",
      "Evluated.. 800\n",
      "Evluated.. 900\n",
      "Evluated.. 1000\n",
      "Evluated.. 1100\n",
      "Evluated.. 1200\n",
      "Evluated.. 1300\n",
      "Evluated.. 1400\n",
      "Evluated.. 1500\n",
      "Evluated.. 1600\n",
      "Evluated.. 1700\n",
      "Evluated.. 1800\n",
      "Evluated.. 1900\n",
      "Evluated.. 2000\n",
      "Evluated.. 2100\n",
      "Evluated.. 2200\n",
      "Evluated.. 2300\n",
      "Evluated.. 2400\n",
      "Evluated.. 2500\n",
      "Evluated.. 2600\n",
      "Evluated.. 2700\n",
      "Evluated.. 2800\n",
      "Evluated.. 2900\n",
      "Evluated.. 3000\n",
      "Evluated.. 3100\n",
      "Evluated.. 3200\n",
      "Evluated.. 3300\n",
      "Evluated.. 3400\n",
      "Evluated.. 3500\n",
      "Evluated.. 3600\n",
      "Evluated.. 3700\n",
      "Evluated.. 3800\n",
      "Evluated.. 3900\n",
      "Evluated.. 4000\n",
      "Evluated.. 4100\n",
      "Evluated.. 4200\n",
      "Evluated.. 4300\n",
      "Evluated.. 4400\n",
      "Evluated.. 4500\n",
      "Evluated.. 4600\n",
      "Evluated.. 4700\n",
      "Evluated.. 4800\n",
      "Evluated.. 4900\n",
      "Evluated.. 5000\n",
      "Evluated.. 5100\n",
      "Evluated.. 5200\n",
      "Evluated.. 5300\n",
      "Evluated.. 5400\n",
      "Evluated.. 5500\n",
      "Evluated.. 5600\n",
      "Evluated.. 5700\n",
      "Evluated.. 5800\n",
      "Evluated.. 5900\n",
      "Evluated.. 6000\n",
      "Evluated.. 6100\n",
      "Evluated.. 6200\n",
      "Evluated.. 6300\n",
      "Evluated.. 6400\n",
      "Evluated.. 6500\n",
      "Evluated.. 6600\n",
      "Evluated.. 6700\n",
      "Evluated.. 6800\n",
      "Evluated.. 6900\n",
      "Evluated.. 7000\n",
      "Evluated.. 7100\n",
      "Evluated.. 7200\n",
      "Evluated.. 7300\n",
      "Evluated.. 7400\n",
      "Evluated.. 7500\n",
      "Evluated.. 7600\n",
      "Evluated.. 7700\n",
      "Evluated.. 7800\n",
      "Evluated.. 7900\n",
      "Evluated.. 8000\n",
      "Evluated.. 8100\n",
      "Evluated.. 8200\n",
      "Evluated.. 8300\n",
      "Evluated.. 8400\n",
      "Evluated.. 8500\n",
      "Evluated.. 8600\n",
      "Evluated.. 8700\n",
      "Evluated.. 8800\n",
      "Evluated.. 8900\n",
      "Evluated.. 9000\n",
      "Evluated.. 9100\n",
      "Evluated.. 9200\n",
      "Evluated.. 9300\n",
      "Evluated.. 9400\n",
      "Evluated.. 9500\n",
      "Evluated.. 9600\n",
      "Evluated.. 9700\n",
      "Evluated.. 9800\n",
      "Evluated.. 9900\n",
      "Evluated.. 10000\n",
      "Evluated.. 10100\n",
      "Evluated.. 10200\n",
      "Evluated.. 10300\n",
      "Evluated.. 10400\n",
      "Evluated.. 10500\n",
      "Evluated.. 10600\n",
      "Evluated.. 10700\n",
      "Evluated.. 10800\n",
      "Evluated.. 10900\n",
      "Evluated.. 11000\n",
      "Evluated.. 11100\n",
      "Evluated.. 11200\n",
      "Evluated.. 11300\n",
      "Evluated.. 11400\n",
      "Evluated.. 11500\n",
      "Evluated.. 11600\n",
      "Evluated.. 11700\n",
      "Evluated.. 11800\n",
      "Evluated.. 11900\n",
      "Evluated.. 12000\n",
      "Evluated.. 12100\n",
      "Evluated.. 12200\n",
      "Evluated.. 12300\n",
      "Evluated.. 12400\n",
      "Evluated.. 12500\n",
      "Evluated.. 12600\n",
      "Evluated.. 12700\n",
      "Evluated.. 12800\n",
      "Evluated.. 12900\n",
      "Evluated.. 13000\n",
      "Evluated.. 13100\n",
      "Evluated.. 13200\n",
      "Evluated.. 13300\n",
      "Evluated.. 13400\n",
      "Evluated.. 13500\n",
      "Evluated.. 13600\n",
      "Evluated.. 13700\n",
      "Evluated.. 13800\n",
      "Evluated.. 13900\n",
      "Evluated.. 14000\n",
      "Evluated.. 14100\n",
      "Evluated.. 14200\n",
      "Evluated.. 14300\n",
      "Evluated.. 14400\n",
      "Evluated.. 14500\n",
      "Evluated.. 14600\n",
      "Evluated.. 14700\n",
      "Evluated.. 14800\n",
      "Evluated.. 14900\n",
      "Evluated.. 15000\n",
      "Evluated.. 15100\n",
      "Evluated.. 15200\n",
      "Evluated.. 15300\n",
      "Evluated.. 15400\n",
      "Evluated.. 15500\n",
      "Evluated.. 15600\n",
      "Evluated.. 15700\n",
      "Evluated.. 15800\n",
      "Evluated.. 15900\n",
      "Evluated.. 16000\n",
      "Evluated.. 16100\n",
      "Evluated.. 16200\n",
      "Evluated.. 16300\n",
      "Evluated.. 16400\n",
      "Evluated.. 16500\n",
      "Evluated.. 16600\n",
      "Evluated.. 16700\n",
      "Evluated.. 16800\n",
      "Evluated.. 16900\n",
      "Evluated.. 17000\n",
      "Evluated.. 17100\n",
      "Evluated.. 17200\n",
      "Evluated.. 17300\n",
      "Evluated.. 17400\n",
      "Evluated.. 17500\n",
      "Evluated.. 17600\n",
      "Evluated.. 17700\n",
      "Evluated.. 17800\n",
      "Evluated.. 17900\n",
      "Evluated.. 18000\n",
      "Evluated.. 18100\n",
      "Evluated.. 18200\n",
      "Evluated.. 18300\n",
      "Evluated.. 18400\n",
      "Evluated.. 18500\n",
      "Evluated.. 18600\n",
      "Evluated.. 18700\n",
      "Evluated.. 18800\n",
      "Evluated.. 18900\n",
      "Evluated.. 19000\n",
      "Evluated.. 19100\n",
      "Evluated.. 19200\n",
      "Evluated.. 19300\n",
      "Evluated.. 19400\n",
      "Evluated.. 19500\n",
      "Evluated.. 19600\n",
      "Evluated.. 19700\n",
      "Evluated.. 19800\n",
      "Evluated.. 19900\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Look at each sub-image in each full sized equation\n",
    "d = [\"+\", \"-\", \"==\"] # Reference dictionary for the symbols, use == so expr() can be used\n",
    "testEvaluations = [] # A list of all of our guesses - in numerical order\n",
    "\n",
    "# Read the old, already correct values\n",
    "correctEvals = []\n",
    "# cDF = pd.read_csv(correctData, names = [\"index\", \"values\"])\n",
    "# cDF = cDF.drop(\"index\", axis = 1)\n",
    "# try:\n",
    "#     cDF = cDF.iloc[1:] # Remove first row of leading 0\n",
    "#     correctList = cDF.values.tolist()\n",
    "#     correctList = [x[0] for x in correctList]\n",
    "# except IndexError:\n",
    "#     correctList = []\n",
    "# startIndex = cDF.shape[0]\n",
    "\n",
    "evalList = []\n",
    "\n",
    "# We use the digit model for all digits (i.e. the 1st, 3rd, and 5th 'image')\n",
    "# and use the symbol model for the symbols (2nd and 4th 'image')\n",
    "for c, image in enumerate(testDL):\n",
    "    image[image < .25] = 0\n",
    "    \n",
    "    char1 = image[:24,   :24].reshape(1, 24, 24, 1)\n",
    "    pred1 = dModel.predict_classes(char1)\n",
    "\n",
    "    char2 = image[:24, 24:48].reshape(1, 24, 24, 1)\n",
    "    pred2 = sModel.predict_classes(char2)\n",
    "\n",
    "    char3 = image[:24, 48:72].reshape(1, 24, 24, 1)\n",
    "    pred3 = dModel.predict_classes(char3)\n",
    "\n",
    "    char4 = image[:24, 72:96].reshape(1, 24, 24, 1)\n",
    "    if pred2 is 0 or 1: # If the previous symbol was arithmetic, we know the next will be an = sign\n",
    "        pred4 = [2]\n",
    "    else: \n",
    "        pred4 = sModel.predict_classes(char4)\n",
    "\n",
    "    char5 = image[:24, 96:  ].reshape(1, 24, 24, 1)\n",
    "    pred5 = dModel.predict_classes(char5)\n",
    "\n",
    "    # Make one array containing each guess\n",
    "    guess = np.concatenate((pred1, pred2, pred3, pred4, pred5))\n",
    "    # Convert each element to either it's string equivalent, or the equiv. sign\n",
    "    expr  = [d[x] if (i in (1, 3)) else str(x) for i, x in enumerate(guess)]\n",
    "    expr = ''.join(expr) # Convert the array to one string\n",
    "        \n",
    "    # Evaluate the single expression - If there was a syntax error, guess a 0    \n",
    "    try: # print (expr, eval(expr))\n",
    "        testEvaluations.append(1 if eval(expr) else 0)\n",
    "    except SyntaxError:\n",
    "        testEvaluations.append(0)\n",
    "    if c % 100 == 0:\n",
    "        print (\"Evluated.. %i\" % c)\n",
    "\n",
    "print (evalList)\n",
    "\n",
    "# correctList.extend(correctEvals)\n",
    "# print (\"Corrected {:.3%} of all the data.\".format(len(correctList) / 20000.0))\n",
    "# correctDF = pd.DataFrame(correctList)\n",
    "# correctDF.to_csv(correctData)\n",
    "\n",
    "dtf = pd.DataFrame(testEvaluations)\n",
    "# dtf.update(correctDF) # Change the first 'n' values to the corrected ones\n",
    "dtf = dtf.astype(int) # Recast the datatype as an integer\n",
    "dtf.to_csv(outputPath) # Change top row to [\"index\", \"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## shiftVal = .125\n",
    "rotationRange = 38\n",
    "zoomRange = .185\n",
    "# datagen = ImageDataGenerator(zoom_range = zoomRange,\n",
    "#                              rotation_range = rotationRange, \n",
    "#                              width_shift_range = shiftVal, height_shift_range = shiftVal)\n",
    "# datagen.fit(x_train_digits)\n",
    "for x_batch in x_train_digits:\n",
    "    for i in range(0, 9):\n",
    "        plt.subplot(330 + 1 + i)\n",
    "        plt.imshow(x_train_digits[i].reshape(24, 24), cmap = plt.get_cmap('gray'))\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
